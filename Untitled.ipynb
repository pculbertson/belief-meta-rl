{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "1\n",
      "-1297.4198379764784 tensor(52.3278, device='cuda:0', grad_fn=<AddBackward0>) tensor(9648.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-872.9649318605071 tensor(48.3995, device='cuda:0', grad_fn=<AddBackward0>) tensor(7608.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-4.76466178894043 45.688758850097656\n",
      "-1210.1953489045343 tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.6844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-6.211590766906738 24.768123626708984\n",
      "-1071.5476524392043 tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>) tensor(7.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.256592273712158 27.11442756652832\n",
      "-862.768538943987 tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.7973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "48.4780158996582 33.958274841308594\n",
      "-1355.6749896613446 tensor(1.1873, device='cuda:0', grad_fn=<AddBackward0>) tensor(8.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.319246292114258 21.09374237060547\n",
      "-871.9027340641832 tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>) tensor(8.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.761419773101807 16.8100528717041\n",
      "-1566.3579298956129 tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>) tensor(20.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.599721431732178 17.980554580688477\n",
      "-747.4616946704444 tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-4.5348801612854 16.972455978393555\n",
      "-1205.1202497899412 tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.928605556488037 13.219217300415039\n",
      "-8.043175261862162\n",
      "-0.344622067834892\n",
      "-0.36454024835125787\n",
      "-0.39526844816413925\n",
      "-0.4392015546552473\n",
      "-0.499836365012549\n",
      "-0.582082244094706\n",
      "-0.6926710776966688\n",
      "-0.8406659860232464\n",
      "-1.0380431976597646\n",
      "-1.3002704615607037\n",
      "-1.646714484728344\n",
      "-2.1005677445139814\n",
      "-2.6877996136814786\n",
      "-3.434471112716474\n",
      "-4.3617771432299355\n",
      "-5.478697467601428\n",
      "-6.773454669834118\n",
      "-8.206958122971928\n",
      "-9.712837572336252\n",
      "-11.207327811418853\n",
      "-12.237869687084794\n",
      "-10.508214258069739\n",
      "-8.891779145200545\n",
      "-7.779853110389442\n",
      "-6.592660767971237\n",
      "-5.616759740036178\n",
      "-4.737886790313672\n",
      "-3.9780314498784306\n",
      "-3.347334430843332\n",
      "-2.8463092371237044\n",
      "-2.469389138376986\n",
      "-2.2085168015090404\n",
      "-2.0560537189670094\n",
      "-2.0067935437747346\n",
      "-2.059141565035855\n",
      "-2.2155875320915963\n",
      "-2.482531155040508\n",
      "-2.869397309065047\n",
      "-3.38687024956309\n",
      "-4.044061365179245\n",
      "-4.8446024169279\n",
      "-5.782112952515949\n",
      "-6.83619065105853\n",
      "-7.970697444557252\n",
      "-9.136033401520079\n",
      "-10.27576073207606\n",
      "-11.335610719777597\n",
      "-10.107676697198444\n",
      "-9.152537916188066\n",
      "-8.159809022756766\n",
      "-7.165345407315081\n",
      "-6.207438868896167\n",
      "-5.3213620494693075\n",
      "-4.534591698027841\n",
      "-3.8644553813853357\n",
      "-3.318539327166351\n",
      "-2.89705048046319\n",
      "-2.5959558356662424\n",
      "-2.4099599487860615\n",
      "-2.334819552697642\n",
      "-2.3688425496240075\n",
      "-2.513584600521677\n",
      "-2.7737708122153593\n",
      "-3.156406470576336\n",
      "-3.6689809272209075\n",
      "-4.316698958504436\n",
      "-5.098880893589433\n",
      "-6.005101657315691\n",
      "-7.012196749470865\n",
      "-8.083621869836158\n",
      "-9.172315880488904\n",
      "-10.226915179321955\n",
      "-11.125687026552164\n",
      "-9.913060548847985\n",
      "-8.821667904203403\n",
      "-7.901412657708406\n",
      "-7.195961157296751\n",
      "-6.739125772078666\n",
      "-6.553564694032044\n",
      "-6.650870369345676\n",
      "-7.031691961643786\n",
      "-7.685018826418416\n",
      "-8.586749614116757\n",
      "-9.69869190336224\n",
      "-10.956086081571334\n",
      "-10.064465338507217\n",
      "-9.10686116005128\n",
      "-8.11321760803696\n",
      "-7.119608768008721\n",
      "-6.164310695356154\n",
      "-5.282324777029305\n",
      "-4.500684758943811\n",
      "-3.836235885856373\n",
      "-3.296157664510853\n",
      "-2.880388119889441\n",
      "-2.5847732016656426\n",
      "-2.404021220687489\n",
      "-2.333980864756005\n",
      "-2.373101928079968\n",
      "-2.5230955076491575\n",
      "-2.7888193129977528\n",
      "-3.1773485229648624\n",
      "-3.696135008723841\n",
      "-4.350194343412086\n",
      "-5.13847695979679\n",
      "-6.050018286794354\n",
      "-7.0610205678643405\n",
      "-8.134356650936803\n",
      "-9.222605952965253\n",
      "-10.274390968057583\n",
      "-11.067237738237809\n",
      "-9.859118399214733\n",
      "-8.774620400220007\n",
      "-7.863470032245747\n",
      "-7.168935854336144\n",
      "-6.7243236876203225\n",
      "-6.551768939352345\n",
      "-6.662355968790188\n",
      "-7.0562143338991135\n",
      "-7.721757602283493\n",
      "-8.634240346858082\n",
      "-9.754817562595656\n",
      "-10.916364113711575\n",
      "-10.021109397142805\n",
      "-9.061104980222023\n",
      "-8.066625830132002\n",
      "-7.073955909147854\n",
      "-6.121343176300552\n",
      "-5.243507251226588\n",
      "-4.467034016998372\n",
      "-3.8082877048596067\n",
      "-3.27404659063514\n",
      "-2.8639867858727612\n",
      "-2.5738396928954637\n",
      "-2.3983223432217553\n",
      "-2.3333785438983017\n",
      "-2.37760140789687\n",
      "-2.532857226568189\n",
      "-2.8041343148984668\n",
      "-3.198573764027259\n",
      "-3.7235838357195346\n",
      "-4.38398291871562\n",
      "-5.17834297938462\n",
      "-6.095153328677958\n",
      "-7.109981649530311\n",
      "-8.185124556619256\n",
      "-9.272816158951642\n",
      "-10.321682212730854\n",
      "-11.008945850491395\n",
      "-9.805444796668574\n",
      "-8.727950429632855\n",
      "-7.825999509285315\n",
      "-7.142455146699391\n",
      "-6.710114193618026\n",
      "-6.550589798346403\n",
      "-6.674458604758274\n",
      "-7.08132888119202\n",
      "-7.7590350481436\n",
      "-8.682185234393467\n",
      "-9.811284261624737\n",
      "-10.87645021418305\n",
      "-9.977611545195046\n",
      "-9.015272795933992\n",
      "-8.020037586991233\n",
      "-7.028390670507224\n",
      "-6.078539522373546\n",
      "-5.204911684719075\n",
      "-4.433640619450971\n",
      "-3.7806111040241634\n",
      "-3.2522058016758995\n",
      "-2.847845930727978\n",
      "-2.5631547875301783\n",
      "-2.3928630080129443\n",
      "-2.3330125993673345\n",
      "-2.3823413417060624\n",
      "-2.5428704006329044\n",
      "-2.8197166125665465\n",
      "-3.2200829020675448\n",
      "-3.7513276940914673\n",
      "-4.41806414691382\n",
      "-5.218477215159799\n",
      "-6.140503640734096\n",
      "-7.15907556801223\n",
      "-8.235920387540485\n",
      "-9.322941307799045\n",
      "-10.368784492919652\n",
      "-10.950816394660057\n",
      "-9.752044972470792\n",
      "-8.681662799499911\n",
      "-7.933591282757656\n",
      "-7.181246423586929\n",
      "-6.451224365663366\n",
      "-5.7689636893228\n",
      "-5.156442877988485\n",
      "-4.6306769091383035\n",
      "-4.203356966144795\n",
      "-3.8815180647192755\n",
      "-3.668823889208132\n",
      "-3.5669897952066405\n",
      "-1152.2412548826912 tensor(28.6444, device='cuda:0', grad_fn=<AddBackward0>) tensor(228.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-6.898808002471924 18.686813354492188\n",
      "-3.5769515275393515\n",
      "-5.059976285260849\n",
      "-4.943407050006048\n",
      "-4.909856926677734\n",
      "-4.9606590856411135\n",
      "-5.095348360665439\n",
      "-5.311517882507811\n",
      "-5.60450550618368\n",
      "-5.966997608293751\n",
      "-6.753823946461349\n",
      "-7.851830462719594\n",
      "-9.21851459039061\n",
      "-10.74969956546941\n",
      "-11.117295639365466\n",
      "-9.957594099668134\n",
      "-8.738708869102588\n",
      "-7.498346362412626\n",
      "-6.374928057881045\n",
      "-5.340571145744285\n",
      "-4.421455452473135\n",
      "-3.636686273884635\n",
      "-2.9914113064897316\n",
      "-2.4803951699511875\n",
      "-2.092531775278595\n",
      "-1.8148780370429927\n",
      "-1.6356173936323808\n",
      "-1.5459478857317137\n",
      "-1.5411075381674888\n",
      "-1.6214047498817046\n",
      "-2.012345860525759\n",
      "-2.7756719577263604\n",
      "-3.962808580411465\n",
      "-5.6276429124176595\n",
      "-7.798699045242111\n",
      "-10.443816258867344\n",
      "-13.445015077811986\n",
      "-15.414391162206668\n",
      "-12.713689542158884\n",
      "-10.807564352092333\n",
      "-8.737625171314821\n",
      "-6.351252548910366\n",
      "-4.556465043980632\n",
      "-3.529714487226622\n",
      "-2.6761513849039837\n",
      "-1.7481352927179017\n",
      "-1.1262691965717908\n",
      "-0.7117870617440523\n",
      "-0.4755592425942691\n",
      "-0.37026229269451316\n",
      "-0.29480248994263786\n",
      "-0.24514193389803907\n",
      "-0.23784649774471683\n",
      "-0.15236626544229376\n",
      "-0.0682214272506927\n",
      "-0.023777302665051906\n",
      "-0.006946795340496687\n",
      "-0.006684625576898859\n",
      "-0.009102161915045273\n",
      "-0.012100832548840174\n",
      "-0.013907344842049306\n",
      "-0.006777400546208375\n",
      "-0.007575772393941984\n",
      "-0.01294920840629212\n",
      "-0.025678167911743165\n",
      "-0.025408391148630815\n",
      "-0.01972264010999399\n",
      "-0.020171861783494612\n",
      "-0.02755720361034898\n",
      "-0.04165758401937616\n",
      "-0.020988794284529298\n",
      "-0.003625501884003587\n",
      "-0.0038578002034943748\n",
      "-0.007901767666786646\n",
      "-0.0019213358628257435\n",
      "-0.005512853232887861\n",
      "-0.011606250048680319\n",
      "-0.0043239098956332715\n",
      "-0.003975933515932283\n",
      "-0.006953941630302003\n",
      "-0.008052103050117068\n",
      "-0.005908484772682405\n",
      "-0.00792511231655467\n",
      "-0.0010499415532932651\n",
      "-0.0017522374536477897\n",
      "-0.0035468683810710284\n",
      "-0.0062985351724380205\n",
      "-0.010317868044075505\n",
      "-0.010550994506841537\n",
      "-0.026820535276295895\n",
      "-0.017497182701991677\n",
      "-0.013730363128183296\n",
      "-0.015869978377821663\n",
      "-0.022191715807772062\n",
      "-0.010951404753270303\n",
      "-0.0062414321978380444\n",
      "-0.008964579800264053\n",
      "-0.008265758113872538\n",
      "-0.02561751209352122\n",
      "-0.004133543310297935\n",
      "-0.0005301357134145774\n",
      "-0.0019305814204526573\n",
      "-0.004943430521192366\n",
      "-0.0070588007164174935\n",
      "-0.009455609331229856\n",
      "-0.013188729038742174\n",
      "-0.011648478925510929\n",
      "-0.004556105698196767\n",
      "-0.006377566604222114\n",
      "-0.01725366087284054\n",
      "-0.007280841730946629\n",
      "-0.011540804392184963\n",
      "-0.01090416101978318\n",
      "-0.01355382152833545\n",
      "-0.004171055862543076\n",
      "-0.003583767557951831\n",
      "-0.004834402802187474\n",
      "-0.00764112990812155\n",
      "-0.011043348676525032\n",
      "-0.01003815473179764\n",
      "-0.012908789312655024\n",
      "-0.010402572163255693\n",
      "-0.014352430251791153\n",
      "-0.02012141767756571\n",
      "-0.03021908402706795\n",
      "-0.014182597338444985\n",
      "-0.002349233122641673\n",
      "-0.0017277017958294335\n",
      "-0.005744703046538072\n",
      "-0.012171673708573225\n",
      "-0.019033865387722667\n",
      "-0.004174104955362137\n",
      "-0.006196940078998255\n",
      "-0.00882240211813892\n",
      "-0.011085160467766865\n",
      "-0.01756843811190381\n",
      "-0.008457463102675226\n",
      "-0.008351652815041808\n",
      "-0.013803361360242341\n",
      "-0.013903538209581399\n",
      "-0.020319720703002492\n",
      "-0.006735452632007211\n",
      "-0.007704124677217783\n",
      "-0.013640840636524569\n",
      "-0.032047540399237164\n",
      "-0.020845946277961346\n",
      "-0.016240685615202272\n",
      "-0.013078158654300962\n",
      "-0.013006671395375488\n",
      "-0.018415134753986828\n",
      "-0.03388718262874572\n",
      "-0.06516449280014432\n",
      "-0.02433051935310885\n",
      "-0.0112901822322177\n",
      "-0.0005499438007783826\n",
      "-0.0007283076422466134\n",
      "-0.002015842573327947\n",
      "-0.00384981801746079\n",
      "-0.004220975915670192\n",
      "-0.006902480442953849\n",
      "-0.006786730732937917\n",
      "-0.011999415761453773\n",
      "-0.019318409126620733\n",
      "-0.004609345688048142\n",
      "-0.00798252297997189\n",
      "-0.022092379307303473\n",
      "-0.023773817153913916\n",
      "-0.015958803104728157\n",
      "-0.01577529064984905\n",
      "-0.023825248745441462\n",
      "-0.039528729123106836\n",
      "-0.050011794291760406\n",
      "-0.015350574572134828\n",
      "-0.0034346750700937354\n",
      "-0.0018006187895569432\n",
      "-0.004506093830979715\n",
      "-0.006865478052055469\n",
      "-0.016850498338405993\n",
      "-0.0055505524187544324\n",
      "-0.012244595806436786\n",
      "-0.005155519947820319\n",
      "-0.009171043393433994\n",
      "-0.0051411336509053045\n",
      "-0.01834098063821911\n",
      "-0.0094073004965254\n",
      "-0.006988422321256306\n",
      "-0.008012223788015726\n",
      "-0.012642426448403637\n",
      "-0.002633529637667821\n",
      "-0.005862768317385094\n",
      "-0.0066420818923269434\n",
      "-0.010539583549595525\n",
      "-0.017726231644561146\n",
      "-0.007057914932584618\n",
      "-0.0049421059657043\n",
      "-0.0006037624588860184\n",
      "-0.004544474512005458\n",
      "-0.01560191182216657\n",
      "-0.012569095478123243\n",
      "-0.008306521453752607\n",
      "-0.007011860237596895\n",
      "-267.27051645214743 tensor(2.5973, device='cuda:0', grad_fn=<AddBackward0>) tensor(12.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.3971710205078125 20.16297149658203\n",
      "-0.006630603522964792\n",
      "-0.2866681868316547\n",
      "-0.29707430088449216\n",
      "-0.3137953056655675\n",
      "-0.33802842202465044\n",
      "-0.37156166779534916\n",
      "-0.4169428129073214\n",
      "-0.47771588897927664\n",
      "-0.5587392843913963\n",
      "-0.6665976905725364\n",
      "-0.8101111936589953\n",
      "-1.0009219699363192\n",
      "-1.2540919214211785\n",
      "-1.5885593154310111\n",
      "-2.027166379117932\n",
      "-2.5957862272052488\n",
      "-3.3208990940022134\n",
      "-4.224948456568548\n",
      "-5.319237604274179\n",
      "-6.595336558331594\n",
      "-8.01792492843616\n",
      "-9.519672653206047\n",
      "-11.398021100591704\n",
      "-12.93667325663113\n",
      "-11.366794673092752\n",
      "-9.636897599798418\n",
      "-7.8322439317321235\n",
      "-6.479950713661033\n",
      "-5.245022431121128\n",
      "-4.16894009844119\n",
      "-3.268619964435246\n",
      "-2.5399124480392143\n",
      "-1.9649894234952612\n",
      "-1.5197342420699942\n",
      "-1.1791788229152278\n",
      "-0.9206830263620829\n",
      "-0.7253601433406556\n",
      "-0.5784251002010208\n",
      "-0.4690249062358194\n",
      "-0.38993229521733896\n",
      "-0.3368226907335876\n",
      "-0.3011868368914769\n",
      "-0.22977511751077254\n",
      "-0.11142905921781616\n",
      "-0.05180632059855403\n",
      "-0.06816779297589054\n",
      "-0.02347717664940096\n",
      "-0.006808586113730861\n",
      "-0.00931100202605392\n",
      "-0.00602226911572833\n",
      "-0.016723724620550686\n",
      "-0.00048478915876531725\n",
      "-0.002521627062873176\n",
      "-0.006648259316208133\n",
      "-0.002841103815244775\n",
      "-0.0017701092559192096\n",
      "-0.0064390469141861785\n",
      "-0.001308844078937225\n",
      "-0.0016440947197472382\n",
      "-0.0024397957847975813\n",
      "-0.009664859136102169\n",
      "-0.001620785142818572\n",
      "-0.002608857188702732\n",
      "-0.009312485996603866\n",
      "-0.007352528439502648\n",
      "-0.0018106547725505867\n",
      "-0.004272666543811301\n",
      "-0.013021417218939492\n",
      "-0.004861062002777844\n",
      "-0.011552050556425608\n",
      "-0.002215795732117932\n",
      "-0.0074896546988707504\n",
      "-0.018144017746389015\n",
      "-0.007312443858975277\n",
      "-0.0051360210660705416\n",
      "-0.003043525138805526\n",
      "-0.004249256765051794\n",
      "-0.007251603413119989\n",
      "-0.0013581468573757192\n",
      "-0.0010652565226096477\n",
      "-0.002675694686749551\n",
      "-0.010220962969238998\n",
      "-0.000731790789629801\n",
      "-0.0035298573754538264\n",
      "-0.014868022012378438\n",
      "-0.0015947180140555594\n",
      "-0.0020145239453973765\n",
      "-0.0018864499206881409\n",
      "-0.00979840873388591\n",
      "-0.004794103017412595\n",
      "-0.012183629318252348\n",
      "-0.0013227869282101685\n",
      "-0.0012629827862872859\n",
      "-0.001336417769228158\n",
      "-0.0018558615680772403\n",
      "-0.005169941930208149\n",
      "-0.012660749671018894\n",
      "-0.0014861790429969235\n",
      "-0.001363065413158878\n",
      "-0.001066907929701869\n",
      "-0.001116949302726148\n",
      "-0.0030697024469589804\n",
      "-0.011795646827358803\n",
      "-0.00045122532960109563\n",
      "-0.0003605539468744762\n",
      "-0.0008429416216769144\n",
      "-0.003193173600386078\n",
      "-0.01054321890017983\n",
      "-0.0047598708049925225\n",
      "-0.004991299154754736\n",
      "-0.006119001785941903\n",
      "-0.013954324875557603\n",
      "-0.0011599327971991691\n",
      "-0.00248665317261039\n",
      "-0.0015927393230366353\n",
      "-0.008255937889404968\n",
      "-0.000800392085348611\n",
      "-0.004818183160679719\n",
      "-0.0076815237403227085\n",
      "-0.004386748100711253\n",
      "-0.0016708655889560316\n",
      "-0.0028805480190082274\n",
      "-0.0023283821809985013\n",
      "-0.0017947422882052784\n",
      "-0.0019806833812298164\n",
      "-0.0071449994371284384\n",
      "-0.005619922089346727\n",
      "-0.011394569861416601\n",
      "-0.0023157731152946403\n",
      "-0.0069011641961190615\n",
      "-0.0001992992045208754\n",
      "-0.0044924825775636565\n",
      "-0.008160425802701704\n",
      "-0.0026080681171456264\n",
      "-0.006459918891762783\n",
      "-0.011053760685266822\n",
      "-0.00139610145121403\n",
      "-0.0037484346760924526\n",
      "-0.01453107854066153\n",
      "-0.003008165650538779\n",
      "-0.009319337316769564\n",
      "-0.004188557021609441\n",
      "-0.006748366084655561\n",
      "-0.013968919596447783\n",
      "-0.022404447072674426\n",
      "-0.015987250093018535\n",
      "-0.012564552198321696\n",
      "-0.017907318153548516\n",
      "-0.007858548433180351\n",
      "-0.009436853725850557\n",
      "-0.012679585716173388\n",
      "-0.02538963818284269\n",
      "-0.006974034799288311\n",
      "-0.01281727631653388\n",
      "-0.003499263821050948\n",
      "-0.0048548311610979045\n",
      "-0.007074324342001572\n",
      "-0.013364831317946423\n",
      "-0.004848551503774977\n",
      "-0.010645212493542331\n",
      "-0.0007179750294305596\n",
      "-0.0021756563562697886\n",
      "-0.010607425360365103\n",
      "-0.001409050341144235\n",
      "-0.0015310363099132443\n",
      "-0.001284189725000082\n",
      "-0.0017414823752401833\n",
      "-0.004773827701564957\n",
      "-0.0031245889048493332\n",
      "-0.00602126321434741\n",
      "-0.0009255686551829691\n",
      "-0.00144967527927162\n",
      "-0.005095317327528412\n",
      "-0.011382229944183756\n",
      "-0.000899920846652074\n",
      "-0.004128759357938678\n",
      "-0.00492928805376375\n",
      "-0.015043994629920777\n",
      "-0.00017704477478732545\n",
      "-0.00010987806575633992\n",
      "-0.0033220316125836093\n",
      "-0.005729643156472481\n",
      "-0.0020130275525853205\n",
      "-0.005106617527690874\n",
      "-0.007270774626581541\n",
      "-0.0010423800768625644\n",
      "-0.002465352793475054\n",
      "-0.011701312552137442\n",
      "-0.001003481809896554\n",
      "-0.0013788234937157971\n",
      "-0.001520497181808461\n",
      "-0.0011522808498093326\n",
      "-0.0044711083005225805\n",
      "-4.803040151647325e-05\n",
      "-0.0006959472864281163\n",
      "-0.0015598009581772308\n",
      "-5.0840355433412975e-05\n",
      "-0.003403886485818946\n",
      "-0.006043388800482053\n",
      "-0.006458036982665148\n",
      "-134.58563529972875 tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7.4697723388671875 22.691688537597656\n",
      "-0.0020903324960069468\n",
      "-0.23481292909550108\n",
      "-0.2046156280022762\n",
      "-0.17680739125629924\n",
      "-0.14043429013756634\n",
      "-0.12168009995321474\n",
      "-0.10520941814427306\n",
      "-0.08616242940760654\n",
      "-0.08531723847258595\n",
      "-0.07359224669463196\n",
      "-0.05059923907042071\n",
      "-0.03935859184934797\n",
      "-0.012090838656655679\n",
      "-0.013953093625017007\n",
      "-0.012299021943376287\n",
      "-0.018162002817916134\n",
      "-0.007655278360746948\n",
      "-0.009600456680033807\n",
      "-0.011013494038366491\n",
      "-0.004725500505486333\n",
      "-0.008154761601947636\n",
      "-0.00499820804775835\n",
      "-0.004862678381547278\n",
      "-0.0053140888499157626\n",
      "-0.006028036064704961\n",
      "-0.003405662307099183\n",
      "-0.00353216620626985\n",
      "-0.007311946763420082\n",
      "-0.003993428320173569\n",
      "-0.0032025696581637953\n",
      "-0.002710243271177181\n",
      "-0.00630368670788548\n",
      "-0.013708006509525243\n",
      "-0.004204084431919441\n",
      "-0.0036788755667513376\n",
      "-0.004557550743459698\n",
      "-0.00928314124559705\n",
      "-0.008396154767987921\n",
      "-0.008697283823328777\n",
      "-0.005056091876778376\n",
      "-0.008181193492819438\n",
      "-0.015489801882799102\n",
      "-0.00794577395315004\n",
      "-0.008330936663443476\n",
      "-0.008288894306463708\n",
      "-0.007762262446209221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-003347e5a38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmbrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/belief-meta-rl/mbrl/mb_train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0maction_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_action_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;31m#a = action_dist.pop(0).sample().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/belief-meta-rl/mbrl/mb_policies.py\u001b[0m in \u001b[0;36mnew_action_dist\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_traj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traj_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traj_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_state_rew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;31m#take elite fraction, refit action distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mtotal_rew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/belief-meta-rl/mbrl/mb_policies.py\u001b[0m in \u001b[0;36m_next_state_rew\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mr_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/belief-meta-rl/mbrl/mb_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mbrl.mb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88594e84883f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10000., grad_fn=<MeanBackward0>)\n",
      "tensor(9409., grad_fn=<MeanBackward0>)\n",
      "tensor(9216., grad_fn=<MeanBackward0>)\n",
      "tensor(9025., grad_fn=<MeanBackward0>)\n",
      "tensor(8836., grad_fn=<MeanBackward0>)\n",
      "tensor(8649., grad_fn=<MeanBackward0>)\n",
      "tensor(8464., grad_fn=<MeanBackward0>)\n",
      "tensor(8281., grad_fn=<MeanBackward0>)\n",
      "tensor(8100., grad_fn=<MeanBackward0>)\n",
      "tensor(7921., grad_fn=<MeanBackward0>)\n",
      "tensor(7744., grad_fn=<MeanBackward0>)\n",
      "tensor(7569., grad_fn=<MeanBackward0>)\n",
      "tensor(7396., grad_fn=<MeanBackward0>)\n",
      "tensor(7225., grad_fn=<MeanBackward0>)\n",
      "tensor(7056., grad_fn=<MeanBackward0>)\n",
      "tensor(6889., grad_fn=<MeanBackward0>)\n",
      "tensor(6724., grad_fn=<MeanBackward0>)\n",
      "tensor(6561., grad_fn=<MeanBackward0>)\n",
      "tensor(6400., grad_fn=<MeanBackward0>)\n",
      "tensor(6241., grad_fn=<MeanBackward0>)\n",
      "tensor(6084., grad_fn=<MeanBackward0>)\n",
      "tensor(5929., grad_fn=<MeanBackward0>)\n",
      "tensor(5776., grad_fn=<MeanBackward0>)\n",
      "tensor(5625., grad_fn=<MeanBackward0>)\n",
      "tensor(5476., grad_fn=<MeanBackward0>)\n",
      "tensor(5329., grad_fn=<MeanBackward0>)\n",
      "tensor(5184., grad_fn=<MeanBackward0>)\n",
      "tensor(5041., grad_fn=<MeanBackward0>)\n",
      "tensor(4900., grad_fn=<MeanBackward0>)\n",
      "tensor(4761., grad_fn=<MeanBackward0>)\n",
      "tensor(4624., grad_fn=<MeanBackward0>)\n",
      "tensor(4489., grad_fn=<MeanBackward0>)\n",
      "tensor(4356., grad_fn=<MeanBackward0>)\n",
      "tensor(4225., grad_fn=<MeanBackward0>)\n",
      "tensor(4096., grad_fn=<MeanBackward0>)\n",
      "tensor(3969., grad_fn=<MeanBackward0>)\n",
      "tensor(3844., grad_fn=<MeanBackward0>)\n",
      "tensor(3721., grad_fn=<MeanBackward0>)\n",
      "tensor(3600., grad_fn=<MeanBackward0>)\n",
      "tensor(3481., grad_fn=<MeanBackward0>)\n",
      "tensor(3364., grad_fn=<MeanBackward0>)\n",
      "tensor(3249., grad_fn=<MeanBackward0>)\n",
      "tensor(3136., grad_fn=<MeanBackward0>)\n",
      "tensor(3025., grad_fn=<MeanBackward0>)\n",
      "tensor(2916., grad_fn=<MeanBackward0>)\n",
      "tensor(2809., grad_fn=<MeanBackward0>)\n",
      "tensor(2704., grad_fn=<MeanBackward0>)\n",
      "tensor(2601., grad_fn=<MeanBackward0>)\n",
      "tensor(2500., grad_fn=<MeanBackward0>)\n",
      "tensor(2401., grad_fn=<MeanBackward0>)\n",
      "tensor(2304., grad_fn=<MeanBackward0>)\n",
      "tensor(2209., grad_fn=<MeanBackward0>)\n",
      "tensor(2116., grad_fn=<MeanBackward0>)\n",
      "tensor(2025., grad_fn=<MeanBackward0>)\n",
      "tensor(1936., grad_fn=<MeanBackward0>)\n",
      "tensor(1849., grad_fn=<MeanBackward0>)\n",
      "tensor(1764., grad_fn=<MeanBackward0>)\n",
      "tensor(1681., grad_fn=<MeanBackward0>)\n",
      "tensor(1600., grad_fn=<MeanBackward0>)\n",
      "tensor(1521., grad_fn=<MeanBackward0>)\n",
      "tensor(1444., grad_fn=<MeanBackward0>)\n",
      "tensor(1369., grad_fn=<MeanBackward0>)\n",
      "tensor(1296., grad_fn=<MeanBackward0>)\n",
      "tensor(1225., grad_fn=<MeanBackward0>)\n",
      "tensor(1156., grad_fn=<MeanBackward0>)\n",
      "tensor(1089., grad_fn=<MeanBackward0>)\n",
      "tensor(1024., grad_fn=<MeanBackward0>)\n",
      "tensor(961., grad_fn=<MeanBackward0>)\n",
      "tensor(900., grad_fn=<MeanBackward0>)\n",
      "tensor(841., grad_fn=<MeanBackward0>)\n",
      "tensor(784., grad_fn=<MeanBackward0>)\n",
      "tensor(729., grad_fn=<MeanBackward0>)\n",
      "tensor(676., grad_fn=<MeanBackward0>)\n",
      "tensor(625., grad_fn=<MeanBackward0>)\n",
      "tensor(576., grad_fn=<MeanBackward0>)\n",
      "tensor(529., grad_fn=<MeanBackward0>)\n",
      "tensor(484., grad_fn=<MeanBackward0>)\n",
      "tensor(441., grad_fn=<MeanBackward0>)\n",
      "tensor(400., grad_fn=<MeanBackward0>)\n",
      "tensor(361., grad_fn=<MeanBackward0>)\n",
      "tensor(324., grad_fn=<MeanBackward0>)\n",
      "tensor(289., grad_fn=<MeanBackward0>)\n",
      "tensor(256., grad_fn=<MeanBackward0>)\n",
      "tensor(225., grad_fn=<MeanBackward0>)\n",
      "tensor(196., grad_fn=<MeanBackward0>)\n",
      "tensor(169., grad_fn=<MeanBackward0>)\n",
      "tensor(144., grad_fn=<MeanBackward0>)\n",
      "tensor(121., grad_fn=<MeanBackward0>)\n",
      "tensor(100., grad_fn=<MeanBackward0>)\n",
      "tensor(81., grad_fn=<MeanBackward0>)\n",
      "tensor(64., grad_fn=<MeanBackward0>)\n",
      "tensor(49., grad_fn=<MeanBackward0>)\n",
      "tensor(36., grad_fn=<MeanBackward0>)\n",
      "tensor(25., grad_fn=<MeanBackward0>)\n",
      "tensor(16., grad_fn=<MeanBackward0>)\n",
      "tensor(9., grad_fn=<MeanBackward0>)\n",
      "tensor(4., grad_fn=<MeanBackward0>)\n",
      "tensor(1., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(1., grad_fn=<MeanBackward0>)\n",
      "tensor(4., grad_fn=<MeanBackward0>)\n",
      "tensor(9., grad_fn=<MeanBackward0>)\n",
      "tensor(16., grad_fn=<MeanBackward0>)\n",
      "tensor(25., grad_fn=<MeanBackward0>)\n",
      "tensor(36., grad_fn=<MeanBackward0>)\n",
      "tensor(49., grad_fn=<MeanBackward0>)\n",
      "tensor(64., grad_fn=<MeanBackward0>)\n",
      "tensor(81., grad_fn=<MeanBackward0>)\n",
      "tensor(100., grad_fn=<MeanBackward0>)\n",
      "tensor(121., grad_fn=<MeanBackward0>)\n",
      "tensor(144., grad_fn=<MeanBackward0>)\n",
      "tensor(169., grad_fn=<MeanBackward0>)\n",
      "tensor(196., grad_fn=<MeanBackward0>)\n",
      "tensor(225., grad_fn=<MeanBackward0>)\n",
      "tensor(256., grad_fn=<MeanBackward0>)\n",
      "tensor(289., grad_fn=<MeanBackward0>)\n",
      "tensor(324., grad_fn=<MeanBackward0>)\n",
      "tensor(361., grad_fn=<MeanBackward0>)\n",
      "tensor(400., grad_fn=<MeanBackward0>)\n",
      "tensor(441., grad_fn=<MeanBackward0>)\n",
      "tensor(484., grad_fn=<MeanBackward0>)\n",
      "tensor(529., grad_fn=<MeanBackward0>)\n",
      "tensor(576., grad_fn=<MeanBackward0>)\n",
      "tensor(625., grad_fn=<MeanBackward0>)\n",
      "tensor(676., grad_fn=<MeanBackward0>)\n",
      "tensor(729., grad_fn=<MeanBackward0>)\n",
      "tensor(784., grad_fn=<MeanBackward0>)\n",
      "tensor(841., grad_fn=<MeanBackward0>)\n",
      "tensor(900., grad_fn=<MeanBackward0>)\n",
      "tensor(961., grad_fn=<MeanBackward0>)\n",
      "tensor(1024., grad_fn=<MeanBackward0>)\n",
      "tensor(1089., grad_fn=<MeanBackward0>)\n",
      "tensor(1156., grad_fn=<MeanBackward0>)\n",
      "tensor(1225., grad_fn=<MeanBackward0>)\n",
      "tensor(1296., grad_fn=<MeanBackward0>)\n",
      "tensor(1369., grad_fn=<MeanBackward0>)\n",
      "tensor(1444., grad_fn=<MeanBackward0>)\n",
      "tensor(1521., grad_fn=<MeanBackward0>)\n",
      "tensor(1600., grad_fn=<MeanBackward0>)\n",
      "tensor(1681., grad_fn=<MeanBackward0>)\n",
      "tensor(1764., grad_fn=<MeanBackward0>)\n",
      "tensor(1849., grad_fn=<MeanBackward0>)\n",
      "tensor(1936., grad_fn=<MeanBackward0>)\n",
      "tensor(2025., grad_fn=<MeanBackward0>)\n",
      "tensor(2116., grad_fn=<MeanBackward0>)\n",
      "tensor(2209., grad_fn=<MeanBackward0>)\n",
      "tensor(2304., grad_fn=<MeanBackward0>)\n",
      "tensor(2401., grad_fn=<MeanBackward0>)\n",
      "tensor(2500., grad_fn=<MeanBackward0>)\n",
      "tensor(2601., grad_fn=<MeanBackward0>)\n",
      "tensor(2704., grad_fn=<MeanBackward0>)\n",
      "tensor(2809., grad_fn=<MeanBackward0>)\n",
      "tensor(2916., grad_fn=<MeanBackward0>)\n",
      "tensor(3025., grad_fn=<MeanBackward0>)\n",
      "tensor(3136., grad_fn=<MeanBackward0>)\n",
      "tensor(3249., grad_fn=<MeanBackward0>)\n",
      "tensor(3364., grad_fn=<MeanBackward0>)\n",
      "tensor(3481., grad_fn=<MeanBackward0>)\n",
      "tensor(3600., grad_fn=<MeanBackward0>)\n",
      "tensor(3721., grad_fn=<MeanBackward0>)\n",
      "tensor(3844., grad_fn=<MeanBackward0>)\n",
      "tensor(3969., grad_fn=<MeanBackward0>)\n",
      "tensor(4096., grad_fn=<MeanBackward0>)\n",
      "tensor(4225., grad_fn=<MeanBackward0>)\n",
      "tensor(4356., grad_fn=<MeanBackward0>)\n",
      "tensor(4489., grad_fn=<MeanBackward0>)\n",
      "tensor(4624., grad_fn=<MeanBackward0>)\n",
      "tensor(4761., grad_fn=<MeanBackward0>)\n",
      "tensor(4900., grad_fn=<MeanBackward0>)\n",
      "tensor(5041., grad_fn=<MeanBackward0>)\n",
      "tensor(5184., grad_fn=<MeanBackward0>)\n",
      "tensor(5329., grad_fn=<MeanBackward0>)\n",
      "tensor(5476., grad_fn=<MeanBackward0>)\n",
      "tensor(5625., grad_fn=<MeanBackward0>)\n",
      "tensor(5776., grad_fn=<MeanBackward0>)\n",
      "tensor(5929., grad_fn=<MeanBackward0>)\n",
      "tensor(6084., grad_fn=<MeanBackward0>)\n",
      "tensor(6241., grad_fn=<MeanBackward0>)\n",
      "tensor(6400., grad_fn=<MeanBackward0>)\n",
      "tensor(6561., grad_fn=<MeanBackward0>)\n",
      "tensor(6724., grad_fn=<MeanBackward0>)\n",
      "tensor(6889., grad_fn=<MeanBackward0>)\n",
      "tensor(7056., grad_fn=<MeanBackward0>)\n",
      "tensor(7225., grad_fn=<MeanBackward0>)\n",
      "tensor(7396., grad_fn=<MeanBackward0>)\n",
      "tensor(7569., grad_fn=<MeanBackward0>)\n",
      "tensor(7744., grad_fn=<MeanBackward0>)\n",
      "tensor(7921., grad_fn=<MeanBackward0>)\n",
      "tensor(8100., grad_fn=<MeanBackward0>)\n",
      "tensor(8281., grad_fn=<MeanBackward0>)\n",
      "tensor(8464., grad_fn=<MeanBackward0>)\n",
      "tensor(8649., grad_fn=<MeanBackward0>)\n",
      "tensor(8836., grad_fn=<MeanBackward0>)\n",
      "tensor(9025., grad_fn=<MeanBackward0>)\n",
      "tensor(9216., grad_fn=<MeanBackward0>)\n",
      "tensor(9409., grad_fn=<MeanBackward0>)\n",
      "tensor(9604., grad_fn=<MeanBackward0>)\n",
      "tensor(9801., grad_fn=<MeanBackward0>)\n",
      "tensor(10000., grad_fn=<MeanBackward0>)\n",
      "tensor(10201., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.Tensor([100.]),requires_grad=True)\n",
    "opt = torch.optim.Adam([x],lr=2)\n",
    "for i in range(200):\n",
    "    opt.zero_grad()\n",
    "    loss = torch.mean(torch.pow(x,2))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    x = torch.autograd.Variable(x-1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2377, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1883, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1788, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1381, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0746, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0424, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0422, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0553, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0300, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0305, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    x = torch.from_numpy(np.random.rand(32,2)).float()\n",
    "    y = torch.pow(x,2)\n",
    "    out = net(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(out,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from utils import ReplayBuffer\n",
    "env = gym.make('CartPole-v1')\n",
    "s = env.reset()\n",
    "dim_actions = env.action_space.shape[0] if env.action_space.shape else 1 #if discrete return dim = 1\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "rb = ReplayBuffer(100,dim_obs,dim_actions)\n",
    "for _ in range(1000):\n",
    "    #env.render()\n",
    "    a = env.action_space.sample()\n",
    "    sp, r, d, _ = env.step(a) # take a random action\n",
    "    rb.add_sample(s,a,r,sp,d)\n",
    "    s = env.reset() if d else sp\n",
    "env.close()\n",
    "samps = rb.random_batch(30)\n",
    "np.concatenate((samps['o'],samps['a']),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5289, -0.4686,  0.2360,  0.4785,  0.0261, -0.0652],\n",
       "        [-0.0242,  0.5782,  2.1311, -2.1791, -0.7854,  1.0887]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covs = torch.randn(2,6)\n",
    "mat = torch.zeros(2,3,3)\n",
    "#mat[:,np.tril_indices(1,1)]\n",
    "#mat[np.tril_indices(2,1)] =1\n",
    "#mat\n",
    "covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[:,torch.tril(torch.ones(3,3))==1] = covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([1,2]).reshape(2,1,1)*(torch.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1658, 0.2148, 0.0228, 0.5007],\n",
       "        [0.3972, 0.6224, 0.8517, 0.0791],\n",
       "        [0.7876, 0.9865, 0.7391, 0.6301],\n",
       "        [0.6965, 0.9714, 0.7745, 0.4248],\n",
       "        [0.8680, 0.5124, 0.7352, 0.8702]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.rand(5,3)\n",
    "a = torch.rand(5,1)\n",
    "torch.cat((s,a),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import log_transition_probs, get_batch_mvnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7062e+01, -3.1918e+01, -1.0628e+00, -1.1333e+03, -1.0930e+02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = torch.rand(5,3)\n",
    "covs = torch.rand(5,6)\n",
    "states = torch.rand(5,3)\n",
    "log_probs = log_transition_probs(means,covs,states,cov_type='dense')\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6891,  0.3062,  0.7501],\n",
       "        [ 0.6415,  0.3458,  0.4856],\n",
       "        [ 0.0277,  0.4120,  0.4778],\n",
       "        [ 0.6466,  0.5819, -0.1037],\n",
       "        [ 1.3901,  0.1359, -0.4774]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = torch.rand(5,3)\n",
    "covs = torch.rand(5,1)\n",
    "batch_mvnormal = get_batch_mvnormal(means,covs,cov_type='scalar')\n",
    "batch_mvnormal.rsample()\n",
    "#states = torch.rand(5,3)\n",
    "#log_probs = log_transition_probs(means,covs,states,cov_type='scalar')\n",
    "#log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2744,  0.2780]],\n",
      "\n",
      "        [[ 1.0681,  0.7744]],\n",
      "\n",
      "        [[ 1.4683, -0.0703]],\n",
      "\n",
      "        [[-1.2652,  0.0834]],\n",
      "\n",
      "        [[ 0.5351, -0.6650]],\n",
      "\n",
      "        [[ 1.1666, -1.0228]],\n",
      "\n",
      "        [[-0.2307, -0.4652]],\n",
      "\n",
      "        [[ 1.4199,  0.4385]],\n",
      "\n",
      "        [[-0.4737,  0.7430]],\n",
      "\n",
      "        [[ 1.7689,  2.4899]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dist = torch.distributions.MultivariateNormal(torch.tensor([0.,0.]),torch.eye(2)).expand((10,1))\n",
    "actions = [action_dist.rsample(), action_dist.rsample()]\n",
    "a = torch.squeeze(actions[0][5])\n",
    "print(actions[0])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0851, -0.7500,  0.9306, -0.1238],\n",
       "         [-0.1787, -0.1324,  0.3054,  0.3038],\n",
       "         [ 0.7527,  0.0683, -0.5953, -0.0462],\n",
       "         [-0.7374, -0.5521, -0.7986, -0.8180],\n",
       "         [ 0.0134, -0.1800,  0.9490,  0.9197],\n",
       "         [ 0.8479,  0.4348, -0.6761, -0.7077],\n",
       "         [-0.6510, -0.9942,  0.1193, -0.3231],\n",
       "         [-0.7327, -0.2273, -0.3349,  0.1162],\n",
       "         [ 0.6755,  0.8566, -0.6012, -0.6371],\n",
       "         [-0.7234,  0.7621, -0.5866, -0.9055]],\n",
       "\n",
       "        [[ 0.4837,  0.2461, -0.9551, -0.9397],\n",
       "         [ 0.5994,  0.0471,  0.1242, -0.6162],\n",
       "         [ 0.0646,  0.8224,  0.9204,  0.8039],\n",
       "         [ 0.9588, -0.2995, -0.9291, -0.6867],\n",
       "         [-0.1848, -0.3902,  0.7221,  0.7367],\n",
       "         [-0.8444,  0.7846, -0.2759,  0.4150],\n",
       "         [ 0.6599, -0.5897, -0.9355, -0.2900],\n",
       "         [-0.4827, -0.0561, -0.1914,  0.6026],\n",
       "         [ 0.4880,  0.4498,  0.9157,  0.8063],\n",
       "         [-0.8499, -0.8106, -0.2708, -0.6299]],\n",
       "\n",
       "        [[-0.7631,  0.9493,  0.6466,  0.3353],\n",
       "         [ 0.8235,  0.9739,  0.2194,  0.8858],\n",
       "         [ 0.1410, -0.8670,  0.2263,  0.6592],\n",
       "         [ 0.4064,  0.1155, -0.2319,  0.5266],\n",
       "         [ 0.1948, -0.6153, -0.3676, -0.6670],\n",
       "         [ 0.8435, -0.4740, -0.2497, -0.1515],\n",
       "         [ 0.9781, -0.2548, -0.8036,  0.5303],\n",
       "         [ 0.3799, -0.7275, -0.5082,  0.3716],\n",
       "         [ 0.2190, -0.6838, -0.8121,  0.3968],\n",
       "         [ 0.5921, -0.9500,  0.4276,  0.8302]],\n",
       "\n",
       "        [[-0.8107, -0.5496, -0.7661,  0.9883],\n",
       "         [ 0.0097, -0.0264,  0.5670,  0.7721],\n",
       "         [-0.2199, -0.8820,  0.1743, -0.4598],\n",
       "         [ 0.5242,  0.2378, -0.5383, -0.9454],\n",
       "         [ 0.6979, -0.8368,  0.4772, -0.6929],\n",
       "         [-0.5004,  0.3456, -0.5743, -0.0185],\n",
       "         [-0.5338,  0.2290,  0.5243,  0.9374],\n",
       "         [-0.7508,  0.4970, -0.6375,  0.6821],\n",
       "         [-0.9884, -0.4165,  0.6288, -0.1191],\n",
       "         [-0.4623, -0.4130, -0.0419, -0.6872]],\n",
       "\n",
       "        [[ 0.4480,  0.5698, -0.8882, -0.1566],\n",
       "         [-0.0639,  0.2983, -0.5233, -0.3220],\n",
       "         [ 0.1757,  0.3435, -0.9510, -0.3823],\n",
       "         [ 0.2273, -0.1511,  0.5341, -0.4923],\n",
       "         [ 0.8180,  0.2821, -0.6432,  0.2874],\n",
       "         [ 0.4835, -0.9519, -0.7953, -0.8047],\n",
       "         [ 0.4090, -0.1207,  0.1446,  0.6342],\n",
       "         [ 0.4680, -0.0739, -0.1491,  0.8140],\n",
       "         [ 0.1876,  0.5226,  0.0267,  0.4974],\n",
       "         [-0.1664,  0.8344,  0.8849, -0.6195]],\n",
       "\n",
       "        [[-0.6419, -0.2521, -0.8411, -0.1725],\n",
       "         [ 0.7716, -0.4046, -0.0423,  0.5298],\n",
       "         [-0.9132, -0.9040,  0.3699,  0.1755],\n",
       "         [-0.9317, -0.8118,  0.5589, -0.7652],\n",
       "         [ 0.7169,  0.0832,  0.5232,  0.5151],\n",
       "         [-0.1033, -0.2353,  0.1410,  0.6598],\n",
       "         [-0.0978,  0.2326, -0.0902, -0.0883],\n",
       "         [ 0.9772,  0.9415, -0.2795, -0.9878],\n",
       "         [ 0.7353,  0.2965,  0.2211,  0.3312],\n",
       "         [-0.0756, -0.7568, -0.9536, -0.1825]],\n",
       "\n",
       "        [[-0.6913, -0.5771,  0.5503,  0.7118],\n",
       "         [ 0.1496,  0.2905,  0.0073,  0.4073],\n",
       "         [-0.2841, -0.6671,  0.2167,  0.5200],\n",
       "         [ 0.3036, -0.7988,  0.9143,  0.3336],\n",
       "         [-0.0262,  0.1723, -0.5938,  0.6509],\n",
       "         [ 0.6772,  0.0595,  0.7131, -0.6525],\n",
       "         [ 0.1071, -0.3856,  0.9158,  0.1134],\n",
       "         [-0.0833,  0.0688,  0.4467, -0.6533],\n",
       "         [ 0.6386,  0.5585,  0.1051, -0.7855],\n",
       "         [ 0.8430, -0.5827, -0.0561,  0.4781]],\n",
       "\n",
       "        [[ 0.6274,  0.6969,  0.9510, -0.9963],\n",
       "         [ 0.6441,  0.4657,  0.7634, -0.3737],\n",
       "         [ 0.0337,  0.3724,  0.5109, -0.9468],\n",
       "         [ 0.7173, -0.7071, -0.1881, -0.3896],\n",
       "         [ 0.8161, -0.0993, -0.5460,  0.1185],\n",
       "         [ 0.9038,  0.4724, -0.7781, -0.8836],\n",
       "         [ 0.7342,  0.0440,  0.5054, -0.2473],\n",
       "         [-0.3144,  0.3505, -0.3836,  0.8150],\n",
       "         [ 0.7219, -0.3344,  0.0457,  0.9583],\n",
       "         [-0.1680, -0.6491, -0.4894, -0.8230]],\n",
       "\n",
       "        [[ 0.8522, -0.5810,  0.5765, -0.3009],\n",
       "         [ 0.0034, -0.5075,  0.6072,  0.9678],\n",
       "         [-0.6299,  0.1822,  0.7455, -0.1091],\n",
       "         [-0.2296, -0.4481,  0.1299, -0.1136],\n",
       "         [-0.2983, -0.8458, -0.5934,  0.4324],\n",
       "         [-0.0630, -0.2166, -0.8754, -0.8126],\n",
       "         [-0.1590,  0.3222,  0.6757, -0.4174],\n",
       "         [-0.8979, -0.2767,  0.6873, -0.5183],\n",
       "         [-0.4306, -0.8641, -0.0597,  0.1623],\n",
       "         [ 0.8169,  0.3924,  0.1711,  0.5282]],\n",
       "\n",
       "        [[-0.6963,  0.8857,  0.1085, -0.4111],\n",
       "         [-0.0387, -0.8189,  0.9898,  0.2184],\n",
       "         [ 0.0017,  0.2996,  0.1103,  0.1345],\n",
       "         [-0.2769, -0.9750,  0.7940, -0.6701],\n",
       "         [-0.8139,  0.1465, -0.2399,  0.8026],\n",
       "         [ 0.8457,  0.0025,  0.7596,  0.9791],\n",
       "         [ 0.4404, -0.2427,  0.2946, -0.4630],\n",
       "         [-0.2213, -0.5913,  0.3626, -0.4933],\n",
       "         [-0.7420, -0.5461, -0.0420, -0.5715],\n",
       "         [-0.5221,  0.2607, -0.7666,  0.1335]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "action_dist = torch.distributions.Uniform(torch.from_numpy(env.action_space.low),torch.from_numpy(env.action_space.high))\n",
    "action_dist.expand((10,4)).rsample([10])\n",
    "#env.action_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preston/Documents/school/cs330/env/lib/python3.7/site-packages/ipykernel_launcher.py:69: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.5912) tensor(0.0461)\n",
      "tensor(811.0712) tensor(0.0085)\n",
      "tensor(15.8020) tensor(0.0067)\n",
      "tensor(144.1985) tensor(0.0050)\n",
      "tensor(1.0001) tensor(0.0057)\n",
      "tensor(1.2443) tensor(0.0031)\n",
      "tensor(1.3205) tensor(0.0032)\n",
      "tensor(0.4118) tensor(0.0029)\n",
      "tensor(4.4241) tensor(0.0017)\n",
      "tensor(1.0975) tensor(0.0013)\n",
      "tensor(331.4567) tensor(0.0030)\n",
      "tensor(5.9273) tensor(0.0018)\n",
      "tensor(0.8683) tensor(0.0012)\n",
      "tensor(2.9085) tensor(0.0013)\n",
      "tensor(1.5601) tensor(0.0021)\n",
      "tensor(-0.7317) tensor(0.0010)\n",
      "tensor(1.3513) tensor(0.0008)\n",
      "tensor(-0.7655) tensor(0.0007)\n",
      "tensor(-0.2190) tensor(0.0007)\n",
      "tensor(0.4857) tensor(0.0010)\n",
      "tensor(0.4297) tensor(0.0004)\n",
      "tensor(-0.3431) tensor(0.0004)\n",
      "tensor(3.4557) tensor(0.0004)\n",
      "tensor(-0.9240) tensor(0.0006)\n",
      "tensor(-0.7893) tensor(0.0009)\n",
      "tensor(-0.9749) tensor(0.0005)\n",
      "tensor(-0.2855) tensor(0.0005)\n",
      "tensor(-0.8577) tensor(0.0003)\n",
      "tensor(8.4693) tensor(0.0007)\n",
      "tensor(1.4233) tensor(0.0006)\n",
      "tensor(2.7791) tensor(0.0005)\n",
      "tensor(0.3305) tensor(0.0009)\n",
      "tensor(0.3358) tensor(0.0009)\n",
      "tensor(2.9812) tensor(0.0006)\n",
      "tensor(-0.9504) tensor(0.0004)\n",
      "tensor(-0.2843) tensor(0.0005)\n",
      "tensor(-0.3460) tensor(0.0004)\n",
      "tensor(-1.2635) tensor(0.0003)\n",
      "tensor(45.1795) tensor(0.0003)\n",
      "tensor(0.0011) tensor(0.0003)\n",
      "tensor(15.1228) tensor(0.0006)\n",
      "tensor(-0.3707) tensor(0.0005)\n",
      "tensor(13.3124) tensor(0.0003)\n",
      "tensor(1.6867) tensor(0.0004)\n",
      "tensor(47.7541) tensor(0.0003)\n",
      "tensor(-1.0284) tensor(0.0003)\n",
      "tensor(-1.0190) tensor(0.0004)\n",
      "tensor(0.1861) tensor(0.0009)\n",
      "tensor(-0.8146) tensor(0.0004)\n",
      "tensor(19.6211) tensor(0.0005)\n",
      "tensor(1.1192) tensor(0.0003)\n",
      "tensor(18.7884) tensor(0.0004)\n",
      "tensor(-0.6963) tensor(0.0003)\n",
      "tensor(1.6953) tensor(0.0005)\n",
      "tensor(-0.6816) tensor(0.0011)\n",
      "tensor(-0.3323) tensor(0.0005)\n",
      "tensor(375.7408) tensor(0.0004)\n",
      "tensor(-0.9305) tensor(0.0002)\n",
      "tensor(0.3118) tensor(0.0004)\n",
      "tensor(-0.1323) tensor(0.0005)\n",
      "tensor(-0.5066) tensor(0.0009)\n",
      "tensor(-0.9486) tensor(0.0003)\n",
      "tensor(1210.4659) tensor(0.0006)\n",
      "tensor(0.0730) tensor(0.0002)\n",
      "tensor(-0.4100) tensor(0.0007)\n",
      "tensor(-1.3018) tensor(0.0002)\n",
      "tensor(-0.6273) tensor(0.0003)\n",
      "tensor(-1.0388) tensor(0.0002)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-138bf59bd7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0ms_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_noise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0msp_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_noise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mr_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrew_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym, torch\n",
    "import numpy as np\n",
    "from utils import ReplayBuffer, log_transition_probs, log_rew_probs\n",
    "from models import TransitionNet, RewardNet\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "#env = gym.make('SemisuperPendulumNoise-v0')\n",
    "dim_actions = env.action_space.shape[0] if env.action_space.shape else 1 #if discrete return dim = 1\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "\n",
    "buffer_size = 100000\n",
    "rb = ReplayBuffer(buffer_size,dim_obs,dim_actions)\n",
    "\n",
    "num_epochs = 5000\n",
    "global_iters = 0\n",
    "train_iters = 100\n",
    "\n",
    "trans_cov_type='scalar'\n",
    "rew_cov = False\n",
    "trans_hs=64\n",
    "rew_hs=10\n",
    "\n",
    "state_noise = 1e-2\n",
    "rew_noise = 1e-2\n",
    "\n",
    "trans_net = TransitionNet(dim_obs,dim_actions,cov_type=trans_cov_type,hs=trans_hs)\n",
    "rew_net = RewardNet(dim_obs,dim_actions,cov=rew_cov,hs=rew_hs)\n",
    "cov_weight = 0.1\n",
    "\n",
    "t_learning_rate = 1e-4\n",
    "t_optimizer = torch.optim.Adam(trans_net.parameters(),lr=t_learning_rate)\n",
    "\n",
    "r_learning_rate = 5e-4\n",
    "r_optimizer = torch.optim.Adam(rew_net.parameters(),lr=r_learning_rate)\n",
    "batch_size = 64\n",
    "\n",
    "num_traj = 300\n",
    "traj_length = 50\n",
    "if env.action_space.shape():\n",
    "    action_dist = torch.distributions.Uniform(torch.from_numpy(env.action_space.low),torch.from_numpy(env.action_space.high))\n",
    "    action_dist = action_dist.expand(num_traj,dim_actions)\n",
    "else:\n",
    "    action_dist = torch.distributions.Categorical(logits=torch.ones(action_space.n))\n",
    "\n",
    "policy = RandomShooting(trans_net,rew_net,action_dist,num_traj,traj_length,dim_obs,trans_cov_type,rew_cov)\n",
    "\n",
    "print_freq = 5000\n",
    "t_losses = np.array([])\n",
    "r_losses = np.array([])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    s, d = env.reset(), False\n",
    "    while not d:\n",
    "        a = env.action_space.sample()\n",
    "        sp, r, d, _ = env.step(a) # take a random action\n",
    "        s_n = s+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        sp_n = sp+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        r_n = r+np.random.normal(0.,rew_noise)\n",
    "        rb.add_sample(s_n,a,r_n,sp_n,d)\n",
    "        s = env.reset() if d else sp\n",
    "        \n",
    "        if (rb.size() >= batch_size) and (global_iters % train_iters == 0):\n",
    "            #train transition model\n",
    "            t_optimizer.zero_grad()\n",
    "            samps = rb.random_batch(batch_size)\n",
    "            ins = torch.from_numpy(np.concatenate((samps['o'],samps['a']),axis=1)).float()\n",
    "            t_outs = trans_net(ins)\n",
    "            t_means, t_covs = t_outs[:,:dim_obs], t_outs[:,dim_obs:]\n",
    "            mean_loss = torch.nn.MSELoss()(t_means,torch.from_numpy(samps['op']).float())\n",
    "            cov_loss = torch.mean(-log_transition_probs(t_means,t_covs,torch.from_numpy(samps['op']).float(),cov_type=trans_cov_type))\n",
    "            t_loss = cov_loss\n",
    "            #t_loss = mean_loss + cov_weight*cov_loss\n",
    "            #if trans_cov_type:\n",
    "                #t_means, t_covs = t_outs[:,:dim_obs], t_outs[:,dim_obs:]\n",
    "                #t_loss = torch.mean(-log_transition_probs(t_means,t_covs,torch.from_numpy(samps['op']).float(),cov_type=trans_cov_type))\n",
    "            #else:\n",
    "                #t_loss = torch.nn.MSELoss()(t_outs,torch.from_numpy(samps['r']).float())\n",
    "            t_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(trans_net.parameters(),0.1)\n",
    "            t_optimizer.step()\n",
    "            t_losses = np.append(t_losses, t_loss.data.numpy())\n",
    "            \n",
    "            #train reward model\n",
    "            r_optimizer.zero_grad()\n",
    "            r_outs = rew_net(ins)\n",
    "            r_loss = torch.nn.MSELoss()(r_outs,torch.from_numpy(samps['r']).float())\n",
    "            #r_means, r_covs = r_outs[:,0], r_outs[:,1]\n",
    "            #r_loss = torch.mean(-log_rew_probs(r_means,r_covs,torch.from_numpy(samps['r']).float()))\n",
    "            r_loss.backward()\n",
    "            r_optimizer.step()\n",
    "            r_losses = np.append(r_losses, r_loss.data.numpy())\n",
    "            \n",
    "            if global_iters % print_freq == 0:\n",
    "                print(t_loss.data,r_loss.data)\n",
    "                \n",
    "                \n",
    "        global_iters += 1\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "d = False\n",
    "\n",
    "#print(s)\n",
    "#print(sp)\n",
    "#out = trans_net(torch.from_numpy(np.append(s,a)).float())\n",
    "#print(out)\n",
    "\n",
    "errors = np.array([])\n",
    "covs = np.array([])\n",
    "trans_net.eval()\n",
    "rew_net.eval()\n",
    "\n",
    "for i in range(1000):\n",
    "    while not d:\n",
    "        a = env.action_space.sample()\n",
    "        sp, r, d, _ = env.step(a)\n",
    "    \n",
    "        #print(sp)\n",
    "        t_out = trans_net(torch.from_numpy(np.append(s,a)).float().unsqueeze(0))\n",
    "        t_means, t_cov = t_out[:,:dim_obs], t_out[:,dim_obs:]\n",
    "        #print(t_cov.data)\n",
    "        errors = np.append(errors,torch.nn.MSELoss()(t_means.squeeze(),torch.from_numpy(sp).float()).data.numpy())\n",
    "        covs = np.append(covs,t_cov.data.numpy())\n",
    "        #print(t_out.data)\n",
    "    #print(r)\n",
    "    #r_out = rew_net(torch.from_numpy(np.append(s,a)).float())\n",
    "    #print(r_out.data)\n",
    "        s = sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (0) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f792f3a3c292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_transition_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/school/cs330/project/utils.py\u001b[0m in \u001b[0;36mlog_transition_probs\u001b[0;34m(means, covs, ops, cov_type)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'diag'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcov_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mbatch_mvnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 raise ValueError(\"covariance_matrix must be at least two-dimensional, \"\n\u001b[1;32m    134\u001b[0m                                  \"with optional leading batch dimensions\")\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (0) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "log_transition_probs(out[:4],out[4:],torch.from_numpy(sp).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94181e95d1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmvnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "mvnormal = torch.distributions.MultivariateNormal(out[:4],torch.diag(out[4:]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1129.6434478483968 tensor(1295.9244, grad_fn=<AddBackward0>) tensor(8958.7959, grad_fn=<AddBackward0>)\n",
      "5.982701301574707 12.417093276977539\n",
      "-1077.0734548457287 tensor(577.4715, grad_fn=<AddBackward0>) tensor(2714.3765, grad_fn=<AddBackward0>)\n",
      "4.790426254272461 9.580679893493652\n",
      "-973.5991860728554 tensor(289.8677, grad_fn=<AddBackward0>) tensor(1784.9867, grad_fn=<AddBackward0>)\n",
      "3.750845432281494 4.547117710113525\n",
      "-1671.40501813519 tensor(193.9094, grad_fn=<AddBackward0>) tensor(1124.6600, grad_fn=<AddBackward0>)\n",
      "3.0152041912078857 2.1700167655944824\n",
      "-1469.6018093987068 tensor(98.6511, grad_fn=<AddBackward0>) tensor(338.7305, grad_fn=<AddBackward0>)\n",
      "2.5952539443969727 1.4737608432769775\n",
      "-1090.2927990748271 tensor(117.3204, grad_fn=<AddBackward0>) tensor(382.1710, grad_fn=<AddBackward0>)\n",
      "1.8111815452575684 0.7825819849967957\n",
      "-1201.3815940102272 tensor(43.4470, grad_fn=<AddBackward0>) tensor(184.0816, grad_fn=<AddBackward0>)\n",
      "1.4889333248138428 0.7154713273048401\n",
      "-1101.7450771125425 tensor(38.8238, grad_fn=<AddBackward0>) tensor(114.8683, grad_fn=<AddBackward0>)\n",
      "-0.1903926581144333 0.48537084460258484\n",
      "-918.1930846002017 tensor(26.3331, grad_fn=<AddBackward0>) tensor(90.7281, grad_fn=<AddBackward0>)\n",
      "-0.47376546263694763 0.2935464382171631\n",
      "-1229.0479162423858 tensor(9.6755, grad_fn=<AddBackward0>) tensor(95.6614, grad_fn=<AddBackward0>)\n",
      "-1.649924397468567 0.11028315871953964\n",
      "-1032.6122160663208 tensor(29.7184, grad_fn=<AddBackward0>) tensor(124.9681, grad_fn=<AddBackward0>)\n",
      "-1.2437199354171753 0.18616583943367004\n"
     ]
    }
   ],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0aa50773ab66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#plt.plot(covs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#plt.plot(errors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covariance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'errors' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(t_losses)\n",
    "#plt.xlabel('iterations')\n",
    "#plt.ylabel('-log likelihood')\n",
    "#plt.yscale('log')\n",
    "#plt.show()\n",
    "#plt.plot(covs)\n",
    "#plt.plot(errors)\n",
    "plt.scatter(errors,covs**2)\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('covariance')\n",
    "plt.title('Dynamics Error vs. Network Confidence')\n",
    "#plt.plot(errors)\n",
    "plt.show()\n",
    "#plt.savefig('confidence')\n",
    "#covs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
