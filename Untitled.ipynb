{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 1e-2\n",
    "net = NeuralNet(2,20,2)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2377, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1883, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1788, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1381, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1364, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0876, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0672, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0746, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0715, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0424, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0422, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0553, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0300, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0305, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    x = torch.from_numpy(np.random.rand(32,2)).float()\n",
    "    y = torch.pow(x,2)\n",
    "    out = net(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(out,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from utils import ReplayBuffer\n",
    "env = gym.make('CartPole-v1')\n",
    "s = env.reset()\n",
    "dim_actions = env.action_space.shape[0] if env.action_space.shape else 1 #if discrete return dim = 1\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "rb = ReplayBuffer(100,dim_obs,dim_actions)\n",
    "for _ in range(1000):\n",
    "    #env.render()\n",
    "    a = env.action_space.sample()\n",
    "    sp, r, d, _ = env.step(a) # take a random action\n",
    "    rb.add_sample(s,a,r,sp,d)\n",
    "    s = env.reset() if d else sp\n",
    "env.close()\n",
    "samps = rb.random_batch(30)\n",
    "np.concatenate((samps['o'],samps['a']),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5289, -0.4686,  0.2360,  0.4785,  0.0261, -0.0652],\n",
       "        [-0.0242,  0.5782,  2.1311, -2.1791, -0.7854,  1.0887]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covs = torch.randn(2,6)\n",
    "mat = torch.zeros(2,3,3)\n",
    "#mat[:,np.tril_indices(1,1)]\n",
    "#mat[np.tril_indices(2,1)] =1\n",
    "#mat\n",
    "covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[:,torch.tril(torch.ones(3,3))==1] = covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([1,2]).reshape(2,1,1)*(torch.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1658, 0.2148, 0.0228, 0.5007],\n",
       "        [0.3972, 0.6224, 0.8517, 0.0791],\n",
       "        [0.7876, 0.9865, 0.7391, 0.6301],\n",
       "        [0.6965, 0.9714, 0.7745, 0.4248],\n",
       "        [0.8680, 0.5124, 0.7352, 0.8702]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.rand(5,3)\n",
    "a = torch.rand(5,1)\n",
    "torch.cat((s,a),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import log_transition_probs, get_batch_mvnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7062e+01, -3.1918e+01, -1.0628e+00, -1.1333e+03, -1.0930e+02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = torch.rand(5,3)\n",
    "covs = torch.rand(5,6)\n",
    "states = torch.rand(5,3)\n",
    "log_probs = log_transition_probs(means,covs,states,cov_type='dense')\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6891,  0.3062,  0.7501],\n",
       "        [ 0.6415,  0.3458,  0.4856],\n",
       "        [ 0.0277,  0.4120,  0.4778],\n",
       "        [ 0.6466,  0.5819, -0.1037],\n",
       "        [ 1.3901,  0.1359, -0.4774]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = torch.rand(5,3)\n",
    "covs = torch.rand(5,1)\n",
    "batch_mvnormal = get_batch_mvnormal(means,covs,cov_type='scalar')\n",
    "batch_mvnormal.rsample()\n",
    "#states = torch.rand(5,3)\n",
    "#log_probs = log_transition_probs(means,covs,states,cov_type='scalar')\n",
    "#log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2744,  0.2780]],\n",
      "\n",
      "        [[ 1.0681,  0.7744]],\n",
      "\n",
      "        [[ 1.4683, -0.0703]],\n",
      "\n",
      "        [[-1.2652,  0.0834]],\n",
      "\n",
      "        [[ 0.5351, -0.6650]],\n",
      "\n",
      "        [[ 1.1666, -1.0228]],\n",
      "\n",
      "        [[-0.2307, -0.4652]],\n",
      "\n",
      "        [[ 1.4199,  0.4385]],\n",
      "\n",
      "        [[-0.4737,  0.7430]],\n",
      "\n",
      "        [[ 1.7689,  2.4899]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dist = torch.distributions.MultivariateNormal(torch.tensor([0.,0.]),torch.eye(2)).expand((10,1))\n",
    "actions = [action_dist.rsample(), action_dist.rsample()]\n",
    "a = torch.squeeze(actions[0][5])\n",
    "print(actions[0])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0851, -0.7500,  0.9306, -0.1238],\n",
       "         [-0.1787, -0.1324,  0.3054,  0.3038],\n",
       "         [ 0.7527,  0.0683, -0.5953, -0.0462],\n",
       "         [-0.7374, -0.5521, -0.7986, -0.8180],\n",
       "         [ 0.0134, -0.1800,  0.9490,  0.9197],\n",
       "         [ 0.8479,  0.4348, -0.6761, -0.7077],\n",
       "         [-0.6510, -0.9942,  0.1193, -0.3231],\n",
       "         [-0.7327, -0.2273, -0.3349,  0.1162],\n",
       "         [ 0.6755,  0.8566, -0.6012, -0.6371],\n",
       "         [-0.7234,  0.7621, -0.5866, -0.9055]],\n",
       "\n",
       "        [[ 0.4837,  0.2461, -0.9551, -0.9397],\n",
       "         [ 0.5994,  0.0471,  0.1242, -0.6162],\n",
       "         [ 0.0646,  0.8224,  0.9204,  0.8039],\n",
       "         [ 0.9588, -0.2995, -0.9291, -0.6867],\n",
       "         [-0.1848, -0.3902,  0.7221,  0.7367],\n",
       "         [-0.8444,  0.7846, -0.2759,  0.4150],\n",
       "         [ 0.6599, -0.5897, -0.9355, -0.2900],\n",
       "         [-0.4827, -0.0561, -0.1914,  0.6026],\n",
       "         [ 0.4880,  0.4498,  0.9157,  0.8063],\n",
       "         [-0.8499, -0.8106, -0.2708, -0.6299]],\n",
       "\n",
       "        [[-0.7631,  0.9493,  0.6466,  0.3353],\n",
       "         [ 0.8235,  0.9739,  0.2194,  0.8858],\n",
       "         [ 0.1410, -0.8670,  0.2263,  0.6592],\n",
       "         [ 0.4064,  0.1155, -0.2319,  0.5266],\n",
       "         [ 0.1948, -0.6153, -0.3676, -0.6670],\n",
       "         [ 0.8435, -0.4740, -0.2497, -0.1515],\n",
       "         [ 0.9781, -0.2548, -0.8036,  0.5303],\n",
       "         [ 0.3799, -0.7275, -0.5082,  0.3716],\n",
       "         [ 0.2190, -0.6838, -0.8121,  0.3968],\n",
       "         [ 0.5921, -0.9500,  0.4276,  0.8302]],\n",
       "\n",
       "        [[-0.8107, -0.5496, -0.7661,  0.9883],\n",
       "         [ 0.0097, -0.0264,  0.5670,  0.7721],\n",
       "         [-0.2199, -0.8820,  0.1743, -0.4598],\n",
       "         [ 0.5242,  0.2378, -0.5383, -0.9454],\n",
       "         [ 0.6979, -0.8368,  0.4772, -0.6929],\n",
       "         [-0.5004,  0.3456, -0.5743, -0.0185],\n",
       "         [-0.5338,  0.2290,  0.5243,  0.9374],\n",
       "         [-0.7508,  0.4970, -0.6375,  0.6821],\n",
       "         [-0.9884, -0.4165,  0.6288, -0.1191],\n",
       "         [-0.4623, -0.4130, -0.0419, -0.6872]],\n",
       "\n",
       "        [[ 0.4480,  0.5698, -0.8882, -0.1566],\n",
       "         [-0.0639,  0.2983, -0.5233, -0.3220],\n",
       "         [ 0.1757,  0.3435, -0.9510, -0.3823],\n",
       "         [ 0.2273, -0.1511,  0.5341, -0.4923],\n",
       "         [ 0.8180,  0.2821, -0.6432,  0.2874],\n",
       "         [ 0.4835, -0.9519, -0.7953, -0.8047],\n",
       "         [ 0.4090, -0.1207,  0.1446,  0.6342],\n",
       "         [ 0.4680, -0.0739, -0.1491,  0.8140],\n",
       "         [ 0.1876,  0.5226,  0.0267,  0.4974],\n",
       "         [-0.1664,  0.8344,  0.8849, -0.6195]],\n",
       "\n",
       "        [[-0.6419, -0.2521, -0.8411, -0.1725],\n",
       "         [ 0.7716, -0.4046, -0.0423,  0.5298],\n",
       "         [-0.9132, -0.9040,  0.3699,  0.1755],\n",
       "         [-0.9317, -0.8118,  0.5589, -0.7652],\n",
       "         [ 0.7169,  0.0832,  0.5232,  0.5151],\n",
       "         [-0.1033, -0.2353,  0.1410,  0.6598],\n",
       "         [-0.0978,  0.2326, -0.0902, -0.0883],\n",
       "         [ 0.9772,  0.9415, -0.2795, -0.9878],\n",
       "         [ 0.7353,  0.2965,  0.2211,  0.3312],\n",
       "         [-0.0756, -0.7568, -0.9536, -0.1825]],\n",
       "\n",
       "        [[-0.6913, -0.5771,  0.5503,  0.7118],\n",
       "         [ 0.1496,  0.2905,  0.0073,  0.4073],\n",
       "         [-0.2841, -0.6671,  0.2167,  0.5200],\n",
       "         [ 0.3036, -0.7988,  0.9143,  0.3336],\n",
       "         [-0.0262,  0.1723, -0.5938,  0.6509],\n",
       "         [ 0.6772,  0.0595,  0.7131, -0.6525],\n",
       "         [ 0.1071, -0.3856,  0.9158,  0.1134],\n",
       "         [-0.0833,  0.0688,  0.4467, -0.6533],\n",
       "         [ 0.6386,  0.5585,  0.1051, -0.7855],\n",
       "         [ 0.8430, -0.5827, -0.0561,  0.4781]],\n",
       "\n",
       "        [[ 0.6274,  0.6969,  0.9510, -0.9963],\n",
       "         [ 0.6441,  0.4657,  0.7634, -0.3737],\n",
       "         [ 0.0337,  0.3724,  0.5109, -0.9468],\n",
       "         [ 0.7173, -0.7071, -0.1881, -0.3896],\n",
       "         [ 0.8161, -0.0993, -0.5460,  0.1185],\n",
       "         [ 0.9038,  0.4724, -0.7781, -0.8836],\n",
       "         [ 0.7342,  0.0440,  0.5054, -0.2473],\n",
       "         [-0.3144,  0.3505, -0.3836,  0.8150],\n",
       "         [ 0.7219, -0.3344,  0.0457,  0.9583],\n",
       "         [-0.1680, -0.6491, -0.4894, -0.8230]],\n",
       "\n",
       "        [[ 0.8522, -0.5810,  0.5765, -0.3009],\n",
       "         [ 0.0034, -0.5075,  0.6072,  0.9678],\n",
       "         [-0.6299,  0.1822,  0.7455, -0.1091],\n",
       "         [-0.2296, -0.4481,  0.1299, -0.1136],\n",
       "         [-0.2983, -0.8458, -0.5934,  0.4324],\n",
       "         [-0.0630, -0.2166, -0.8754, -0.8126],\n",
       "         [-0.1590,  0.3222,  0.6757, -0.4174],\n",
       "         [-0.8979, -0.2767,  0.6873, -0.5183],\n",
       "         [-0.4306, -0.8641, -0.0597,  0.1623],\n",
       "         [ 0.8169,  0.3924,  0.1711,  0.5282]],\n",
       "\n",
       "        [[-0.6963,  0.8857,  0.1085, -0.4111],\n",
       "         [-0.0387, -0.8189,  0.9898,  0.2184],\n",
       "         [ 0.0017,  0.2996,  0.1103,  0.1345],\n",
       "         [-0.2769, -0.9750,  0.7940, -0.6701],\n",
       "         [-0.8139,  0.1465, -0.2399,  0.8026],\n",
       "         [ 0.8457,  0.0025,  0.7596,  0.9791],\n",
       "         [ 0.4404, -0.2427,  0.2946, -0.4630],\n",
       "         [-0.2213, -0.5913,  0.3626, -0.4933],\n",
       "         [-0.7420, -0.5461, -0.0420, -0.5715],\n",
       "         [-0.5221,  0.2607, -0.7666,  0.1335]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "action_dist = torch.distributions.Uniform(torch.from_numpy(env.action_space.low),torch.from_numpy(env.action_space.high))\n",
    "action_dist.expand((10,4)).rsample([10])\n",
    "#env.action_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preston/Documents/school/cs330/env/lib/python3.7/site-packages/ipykernel_launcher.py:69: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.5912) tensor(0.0461)\n",
      "tensor(811.0712) tensor(0.0085)\n",
      "tensor(15.8020) tensor(0.0067)\n",
      "tensor(144.1985) tensor(0.0050)\n",
      "tensor(1.0001) tensor(0.0057)\n",
      "tensor(1.2443) tensor(0.0031)\n",
      "tensor(1.3205) tensor(0.0032)\n",
      "tensor(0.4118) tensor(0.0029)\n",
      "tensor(4.4241) tensor(0.0017)\n",
      "tensor(1.0975) tensor(0.0013)\n",
      "tensor(331.4567) tensor(0.0030)\n",
      "tensor(5.9273) tensor(0.0018)\n",
      "tensor(0.8683) tensor(0.0012)\n",
      "tensor(2.9085) tensor(0.0013)\n",
      "tensor(1.5601) tensor(0.0021)\n",
      "tensor(-0.7317) tensor(0.0010)\n",
      "tensor(1.3513) tensor(0.0008)\n",
      "tensor(-0.7655) tensor(0.0007)\n",
      "tensor(-0.2190) tensor(0.0007)\n",
      "tensor(0.4857) tensor(0.0010)\n",
      "tensor(0.4297) tensor(0.0004)\n",
      "tensor(-0.3431) tensor(0.0004)\n",
      "tensor(3.4557) tensor(0.0004)\n",
      "tensor(-0.9240) tensor(0.0006)\n",
      "tensor(-0.7893) tensor(0.0009)\n",
      "tensor(-0.9749) tensor(0.0005)\n",
      "tensor(-0.2855) tensor(0.0005)\n",
      "tensor(-0.8577) tensor(0.0003)\n",
      "tensor(8.4693) tensor(0.0007)\n",
      "tensor(1.4233) tensor(0.0006)\n",
      "tensor(2.7791) tensor(0.0005)\n",
      "tensor(0.3305) tensor(0.0009)\n",
      "tensor(0.3358) tensor(0.0009)\n",
      "tensor(2.9812) tensor(0.0006)\n",
      "tensor(-0.9504) tensor(0.0004)\n",
      "tensor(-0.2843) tensor(0.0005)\n",
      "tensor(-0.3460) tensor(0.0004)\n",
      "tensor(-1.2635) tensor(0.0003)\n",
      "tensor(45.1795) tensor(0.0003)\n",
      "tensor(0.0011) tensor(0.0003)\n",
      "tensor(15.1228) tensor(0.0006)\n",
      "tensor(-0.3707) tensor(0.0005)\n",
      "tensor(13.3124) tensor(0.0003)\n",
      "tensor(1.6867) tensor(0.0004)\n",
      "tensor(47.7541) tensor(0.0003)\n",
      "tensor(-1.0284) tensor(0.0003)\n",
      "tensor(-1.0190) tensor(0.0004)\n",
      "tensor(0.1861) tensor(0.0009)\n",
      "tensor(-0.8146) tensor(0.0004)\n",
      "tensor(19.6211) tensor(0.0005)\n",
      "tensor(1.1192) tensor(0.0003)\n",
      "tensor(18.7884) tensor(0.0004)\n",
      "tensor(-0.6963) tensor(0.0003)\n",
      "tensor(1.6953) tensor(0.0005)\n",
      "tensor(-0.6816) tensor(0.0011)\n",
      "tensor(-0.3323) tensor(0.0005)\n",
      "tensor(375.7408) tensor(0.0004)\n",
      "tensor(-0.9305) tensor(0.0002)\n",
      "tensor(0.3118) tensor(0.0004)\n",
      "tensor(-0.1323) tensor(0.0005)\n",
      "tensor(-0.5066) tensor(0.0009)\n",
      "tensor(-0.9486) tensor(0.0003)\n",
      "tensor(1210.4659) tensor(0.0006)\n",
      "tensor(0.0730) tensor(0.0002)\n",
      "tensor(-0.4100) tensor(0.0007)\n",
      "tensor(-1.3018) tensor(0.0002)\n",
      "tensor(-0.6273) tensor(0.0003)\n",
      "tensor(-1.0388) tensor(0.0002)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-138bf59bd7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0ms_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_noise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0msp_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_noise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mr_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrew_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym, torch\n",
    "import numpy as np\n",
    "from utils import ReplayBuffer, log_transition_probs, log_rew_probs\n",
    "from models import TransitionNet, RewardNet\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "#env = gym.make('SemisuperPendulumNoise-v0')\n",
    "dim_actions = env.action_space.shape[0] if env.action_space.shape else 1 #if discrete return dim = 1\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "\n",
    "buffer_size = 100000\n",
    "rb = ReplayBuffer(buffer_size,dim_obs,dim_actions)\n",
    "\n",
    "num_epochs = 5000\n",
    "global_iters = 0\n",
    "train_iters = 100\n",
    "\n",
    "trans_cov_type='scalar'\n",
    "rew_cov = False\n",
    "trans_hs=64\n",
    "rew_hs=10\n",
    "\n",
    "state_noise = 1e-2\n",
    "rew_noise = 1e-2\n",
    "\n",
    "trans_net = TransitionNet(dim_obs,dim_actions,cov_type=trans_cov_type,hs=trans_hs)\n",
    "rew_net = RewardNet(dim_obs,dim_actions,cov=rew_cov,hs=rew_hs)\n",
    "cov_weight = 0.1\n",
    "\n",
    "t_learning_rate = 1e-4\n",
    "t_optimizer = torch.optim.Adam(trans_net.parameters(),lr=t_learning_rate)\n",
    "\n",
    "r_learning_rate = 5e-4\n",
    "r_optimizer = torch.optim.Adam(rew_net.parameters(),lr=r_learning_rate)\n",
    "batch_size = 64\n",
    "\n",
    "num_traj = 300\n",
    "traj_length = 50\n",
    "if env.action_space.shape():\n",
    "    action_dist = torch.distributions.Uniform(torch.from_numpy(env.action_space.low),torch.from_numpy(env.action_space.high))\n",
    "    action_dist = action_dist.expand(num_traj,dim_actions)\n",
    "else:\n",
    "    action_dist = torch.distributions.Categorical(logits=torch.ones(action_space.n))\n",
    "\n",
    "policy = RandomShooting(trans_net,rew_net,action_dist,num_traj,traj_length,dim_obs,trans_cov_type,rew_cov)\n",
    "\n",
    "print_freq = 5000\n",
    "t_losses = np.array([])\n",
    "r_losses = np.array([])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    s, d = env.reset(), False\n",
    "    while not d:\n",
    "        a = env.action_space.sample()\n",
    "        sp, r, d, _ = env.step(a) # take a random action\n",
    "        s_n = s+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        sp_n = sp+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        r_n = r+np.random.normal(0.,rew_noise)\n",
    "        rb.add_sample(s_n,a,r_n,sp_n,d)\n",
    "        s = env.reset() if d else sp\n",
    "        \n",
    "        if (rb.size() >= batch_size) and (global_iters % train_iters == 0):\n",
    "            #train transition model\n",
    "            t_optimizer.zero_grad()\n",
    "            samps = rb.random_batch(batch_size)\n",
    "            ins = torch.from_numpy(np.concatenate((samps['o'],samps['a']),axis=1)).float()\n",
    "            t_outs = trans_net(ins)\n",
    "            t_means, t_covs = t_outs[:,:dim_obs], t_outs[:,dim_obs:]\n",
    "            mean_loss = torch.nn.MSELoss()(t_means,torch.from_numpy(samps['op']).float())\n",
    "            cov_loss = torch.mean(-log_transition_probs(t_means,t_covs,torch.from_numpy(samps['op']).float(),cov_type=trans_cov_type))\n",
    "            t_loss = cov_loss\n",
    "            #t_loss = mean_loss + cov_weight*cov_loss\n",
    "            #if trans_cov_type:\n",
    "                #t_means, t_covs = t_outs[:,:dim_obs], t_outs[:,dim_obs:]\n",
    "                #t_loss = torch.mean(-log_transition_probs(t_means,t_covs,torch.from_numpy(samps['op']).float(),cov_type=trans_cov_type))\n",
    "            #else:\n",
    "                #t_loss = torch.nn.MSELoss()(t_outs,torch.from_numpy(samps['r']).float())\n",
    "            t_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(trans_net.parameters(),0.1)\n",
    "            t_optimizer.step()\n",
    "            t_losses = np.append(t_losses, t_loss.data.numpy())\n",
    "            \n",
    "            #train reward model\n",
    "            r_optimizer.zero_grad()\n",
    "            r_outs = rew_net(ins)\n",
    "            r_loss = torch.nn.MSELoss()(r_outs,torch.from_numpy(samps['r']).float())\n",
    "            #r_means, r_covs = r_outs[:,0], r_outs[:,1]\n",
    "            #r_loss = torch.mean(-log_rew_probs(r_means,r_covs,torch.from_numpy(samps['r']).float()))\n",
    "            r_loss.backward()\n",
    "            r_optimizer.step()\n",
    "            r_losses = np.append(r_losses, r_loss.data.numpy())\n",
    "            \n",
    "            if global_iters % print_freq == 0:\n",
    "                print(t_loss.data,r_loss.data)\n",
    "                \n",
    "                \n",
    "        global_iters += 1\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "d = False\n",
    "\n",
    "#print(s)\n",
    "#print(sp)\n",
    "#out = trans_net(torch.from_numpy(np.append(s,a)).float())\n",
    "#print(out)\n",
    "\n",
    "errors = np.array([])\n",
    "covs = np.array([])\n",
    "trans_net.eval()\n",
    "rew_net.eval()\n",
    "\n",
    "for i in range(1000):\n",
    "    while not d:\n",
    "        a = env.action_space.sample()\n",
    "        sp, r, d, _ = env.step(a)\n",
    "    \n",
    "        #print(sp)\n",
    "        t_out = trans_net(torch.from_numpy(np.append(s,a)).float().unsqueeze(0))\n",
    "        t_means, t_cov = t_out[:,:dim_obs], t_out[:,dim_obs:]\n",
    "        #print(t_cov.data)\n",
    "        errors = np.append(errors,torch.nn.MSELoss()(t_means.squeeze(),torch.from_numpy(sp).float()).data.numpy())\n",
    "        covs = np.append(covs,t_cov.data.numpy())\n",
    "        #print(t_out.data)\n",
    "    #print(r)\n",
    "    #r_out = rew_net(torch.from_numpy(np.append(s,a)).float())\n",
    "    #print(r_out.data)\n",
    "        s = sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (0) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f792f3a3c292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_transition_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/school/cs330/project/utils.py\u001b[0m in \u001b[0;36mlog_transition_probs\u001b[0;34m(means, covs, ops, cov_type)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'diag'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcov_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mbatch_mvnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 raise ValueError(\"covariance_matrix must be at least two-dimensional, \"\n\u001b[1;32m    134\u001b[0m                                  \"with optional leading batch dimensions\")\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (0) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "log_transition_probs(out[:4],out[4:],torch.from_numpy(sp).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94181e95d1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmvnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "mvnormal = torch.distributions.MultivariateNormal(out[:4],torch.diag(out[4:]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1129.6434478483968 tensor(1295.9244, grad_fn=<AddBackward0>) tensor(8958.7959, grad_fn=<AddBackward0>)\n",
      "5.982701301574707 12.417093276977539\n",
      "-1077.0734548457287 tensor(577.4715, grad_fn=<AddBackward0>) tensor(2714.3765, grad_fn=<AddBackward0>)\n",
      "4.790426254272461 9.580679893493652\n",
      "-973.5991860728554 tensor(289.8677, grad_fn=<AddBackward0>) tensor(1784.9867, grad_fn=<AddBackward0>)\n",
      "3.750845432281494 4.547117710113525\n",
      "-1671.40501813519 tensor(193.9094, grad_fn=<AddBackward0>) tensor(1124.6600, grad_fn=<AddBackward0>)\n",
      "3.0152041912078857 2.1700167655944824\n",
      "-1469.6018093987068 tensor(98.6511, grad_fn=<AddBackward0>) tensor(338.7305, grad_fn=<AddBackward0>)\n",
      "2.5952539443969727 1.4737608432769775\n",
      "-1090.2927990748271 tensor(117.3204, grad_fn=<AddBackward0>) tensor(382.1710, grad_fn=<AddBackward0>)\n",
      "1.8111815452575684 0.7825819849967957\n",
      "-1201.3815940102272 tensor(43.4470, grad_fn=<AddBackward0>) tensor(184.0816, grad_fn=<AddBackward0>)\n",
      "1.4889333248138428 0.7154713273048401\n",
      "-1101.7450771125425 tensor(38.8238, grad_fn=<AddBackward0>) tensor(114.8683, grad_fn=<AddBackward0>)\n",
      "-0.1903926581144333 0.48537084460258484\n",
      "-918.1930846002017 tensor(26.3331, grad_fn=<AddBackward0>) tensor(90.7281, grad_fn=<AddBackward0>)\n",
      "-0.47376546263694763 0.2935464382171631\n"
     ]
    }
   ],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0aa50773ab66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#plt.plot(covs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#plt.plot(errors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covariance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'errors' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(t_losses)\n",
    "#plt.xlabel('iterations')\n",
    "#plt.ylabel('-log likelihood')\n",
    "#plt.yscale('log')\n",
    "#plt.show()\n",
    "#plt.plot(covs)\n",
    "#plt.plot(errors)\n",
    "plt.scatter(errors,covs**2)\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('covariance')\n",
    "plt.title('Dynamics Error vs. Network Confidence')\n",
    "#plt.plot(errors)\n",
    "plt.show()\n",
    "#plt.savefig('confidence')\n",
    "#covs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs330",
   "language": "python",
   "name": "cs330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
