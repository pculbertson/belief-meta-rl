{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from utils.buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4\n",
      "[ 0.11890073  0.39850731 -0.22082311 -1.06153696]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "#env = gym.make('SemisuperPendulumNoise-v0')\n",
    "if env.action_space.shape:\n",
    "    dim_actions = env.action_space.shape[0]\n",
    "    discrete_actions = False\n",
    "else:\n",
    "    dim_actions = env.action_space.n\n",
    "    discrete_actions = True\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "\n",
    "print(dim_actions, dim_obs)\n",
    "\n",
    "buffer_size = 10000\n",
    "if env.action_space.shape:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,dim_actions)\n",
    "else:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,1)\n",
    "num_episodes = 1\n",
    "iter = 0\n",
    "for i in range(num_episodes):\n",
    "    s, d = env.reset(), False\n",
    "    rb.new_episode()\n",
    "    while not d:\n",
    "        a = env.action_space.sample()\n",
    "        sp, r, d, _ = env.step(a)\n",
    "        rb.add_sample(s,a,r,sp,d)\n",
    "        if iter == 19:\n",
    "            print(s)\n",
    "        iter += 1\n",
    "        s = sp\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "seqs = rb.random_sequences(10,seq_length=20)\n",
    "print(seqs[1]['o'][-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(0,5))\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "-200.0 tensor(102.9085, device='cuda:0', grad_fn=<AddBackward0>) tensor(168.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-3.9487574100494385 0.0011278721503913403\n",
      "-200.0 tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-4.6410722732543945 3.142240529996343e-06\n",
      "-200.0 tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-4.844973087310791 6.742162668160745e-07\n",
      "-200.0 tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.6836e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.566864490509033 5.324766334524611e-07\n",
      "-200.0 tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.9134e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.380547523498535 4.7209783815560513e-07\n",
      "-200.0 tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.9359e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.271930694580078 2.836083581314597e-07\n",
      "-200.0 tensor(0.0370, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.5004e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.390707015991211 2.250806545589512e-07\n",
      "-200.0 tensor(0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.457674026489258 1.6268558056253823e-07\n",
      "-200.0 tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.0144e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5.453503608703613 1.166583558642742e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cad9ee5151fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/belief-meta-rl/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/belief-meta-rl/mb_policies.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mactions_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#print((states[:,:,i].shape,actions_input.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_state_rew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbest_traj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/belief-meta-rl/mb_policies.py\u001b[0m in \u001b[0;36m_next_state_rew\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m\"\"\"helper function to unroll dynamics (batched)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mt_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mt_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_covs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mt_covs_clamped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_covs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_logvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_logvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(range(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.0000],\n",
       "        [0.0000, 0.2000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "dist = torch.distributions.MultivariateNormal(torch.tensor([0,0]),5*torch.eye(2))\n",
    "dist.precision_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.],\n",
       "         [3.]],\n",
       "\n",
       "        [[7.],\n",
       "         [7.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mats = torch.stack((torch.stack((torch.eye(2),2*torch.eye(2))),torch.stack((3*torch.eye(2),4*torch.eye(2)))))\n",
    "vecs = torch.stack((torch.stack((torch.ones(2),torch.ones(2))),torch.stack((torch.ones(2),torch.ones(2))))).unsqueeze(3)\n",
    "torch.sum(torch.matmul(mats,vecs),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distributions import product_of_gaussians, gaussian_product_posterior\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.7647],\n",
      "         [-0.7647]],\n",
      "\n",
      "        [[-0.2500],\n",
      "         [-0.2500]]]), tensor([[[1.7000, 0.0000],\n",
      "         [0.0000, 1.7000]],\n",
      "\n",
      "        [[1.3333, 0.0000],\n",
      "         [0.0000, 1.3333]]]))\n",
      "(tensor([[[[-0.7647],\n",
      "          [-0.7647]]]]), tensor([[[[1.7000, 0.0000],\n",
      "          [0.0000, 1.7000]]]]))\n"
     ]
    }
   ],
   "source": [
    "covs = torch.stack((torch.stack((torch.eye(2),2*torch.eye(2),5*torch.eye(2))),torch.stack((2*torch.eye(2),2*torch.eye(2),3*torch.eye(2)))))\n",
    "means = torch.stack((torch.stack((torch.ones(2),-3*torch.ones(2),-4*torch.ones(2))),torch.stack((torch.ones(2),-3*torch.ones(2),2*torch.ones(2)))))\n",
    "precs = torch.inverse(covs)\n",
    "post = product_of_gaussians(means,precs)\n",
    "print(post)\n",
    "prior = product_of_gaussians(means[0,:2,:].view(1,2,2),precs[0,:2,:,:].view(1,2,2,2))\n",
    "posterior = gaussian_product_posterior(prior[0],prior[1],means[0,-1,:].view(1,2,1),precs[0,-1,:,:].view(1,1,2,2))\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, meta_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71811959  0.69591971 -0.66453942]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-439dc98860ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#sp, r, d, _ = env.step(env._goal-s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make('MetaPendulum-v0')#,randomize_tasks=True,n_tasks=10)\n",
    "#env.reset_task(1)\n",
    "s = env.reset()\n",
    "print(s)\n",
    "#sp, r, d, _ = env.step(env._goal-s)\n",
    "print(r)\n",
    "print(sp,env._goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.3068)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.distributions.MultivariateNormal(50*torch.ones(2),20*torch.eye(2))\n",
    "d2 = torch.distributions.MultivariateNormal(torch.zeros(2),10*torch.eye(2))\n",
    "torch.distributions.kl.kl_divergence(d1,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1.,2.]).view(2,1).expand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.9014])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covs= torch.stack((torch.eye(2),3*torch.eye(2)))\n",
    "means = torch.stack((torch.zeros(2),-1*torch.ones(2)))\n",
    "batch_mv_normal = torch.distributions.MultivariateNormal(means,covs)\n",
    "torch.distributions.kl.kl_divergence(batch_mv_normal,torch.distributions.MultivariateNormal(torch.zeros(2),torch.eye(2)).expand([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, torch, meta_env\n",
    "import numpy as np\n",
    "from utils.buffer import ReplayBuffer\n",
    "from belief_models import SingleEncoder, TransitionNet, RewardNet\n",
    "from utils.distributions import get_cov_mat, log_transition_probs, log_rew_probs, product_of_gaussians\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#setup environment\n",
    "env = gym.make('MetaPendulum-v0')\n",
    "if env.action_space.shape:\n",
    "    dim_actions = env.action_space.shape[0]\n",
    "    discrete_actions = False\n",
    "else:\n",
    "    dim_actions = env.action_space.n\n",
    "    discrete_actions = True\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "\n",
    "#setup buffer\n",
    "buffer_size = 10000\n",
    "if env.action_space.shape:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,dim_actions)\n",
    "else:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,1)\n",
    "\n",
    "#training hyperparameters\n",
    "num_epochs = 5000\n",
    "global_iters = 0\n",
    "num_train_steps = 10\n",
    "max_logvar = 10.\n",
    "state_noise = 1e-3\n",
    "rew_noise = 1e-3\n",
    "max_variance = 1.0\n",
    "random_episodes=num_epochs\n",
    "max_ep_length = 300\n",
    "\n",
    "#model hyperparameters\n",
    "trans_cov_type='diag'\n",
    "trans_hs=200\n",
    "\n",
    "rew_hs=200\n",
    "\n",
    "encoder_type = 'single'\n",
    "encoder_cov_type='diag'\n",
    "encoder_hs = 200\n",
    "latent_dim=30\n",
    "latent_prior = torch.distributions.MultivariateNormal(torch.zeros(latent_dim),torch.eye(latent_dim))\n",
    "\n",
    "trans_net = TransitionNet(dim_obs,dim_actions,latent_dim,cov_type=trans_cov_type,hs=trans_hs).to(device)\n",
    "rew_net = RewardNet(dim_obs,dim_actions,latent_dim,hs=rew_hs).to(device)\n",
    "if encoder_type == 'single':\n",
    "    encoder = SingleEncoder(dim_obs,dim_actions,latent_dim,cov_type=encoder_cov_type,hs=encoder_hs)\n",
    "#TODO: code multi-step encoder [RNN]\n",
    "\n",
    "#training parameters\n",
    "t_learning_rate = 1e-3\n",
    "t_optimizer = torch.optim.Adam(trans_net.parameters(),lr=t_learning_rate)\n",
    "\n",
    "r_learning_rate = 1e-3\n",
    "r_optimizer = torch.optim.Adam(rew_net.parameters(),lr=r_learning_rate)\n",
    "\n",
    "q_learning_rate = 1e-3\n",
    "q_optimizer = torch.optim.Adam(encoder.parameters(),lr=q_learning_rate)\n",
    "\n",
    "batch_size = 50\n",
    "batch_length = 50\n",
    "\n",
    "#planner hyperparameters\n",
    "num_traj = 1000\n",
    "traj_length = 30\n",
    "num_iters = 5\n",
    "elite_frac = 0.1\n",
    "\n",
    "#TODO: code planner\n",
    "\n",
    "losses = np.array([])\n",
    "rewards = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rb.new_episode()\n",
    "    if epoch > 0:\n",
    "        for step in range(num_train_steps):\n",
    "            samps = rb.random_sequences(batch_size,batch_length)\n",
    "            \n",
    "            q_optimizer.zero_grad()\n",
    "            t_optimizer.zero_grad()\n",
    "            r_optimizer.zero_grad()\n",
    "            \n",
    "            kl_divs, log_ts, log_rs = torch.zeros(batch_size), torch.zeros(batch_size), torch.zeros(batch_size)\n",
    "        \n",
    "            batch_means, batch_precs, batch_prod_means, batch_prod_precs = [], [], [], []\n",
    "            for i in range(batch_size):\n",
    "                s,a_rb,r,sp = [torch.from_numpy(samps[i][k]).float() for k in ['o','a','r','op']]\n",
    "                if discrete_actions:\n",
    "                    a = torch.squeeze(torch.nn.functional.one_hot(torch.from_numpy(a_rb).long(),num_classes=dim_actions)).float()\n",
    "                else:\n",
    "                    a = a_rb\n",
    "                q_ins = torch.cat((s,a,r,sp),axis=1)\n",
    "                q_outs = encoder(q_ins)\n",
    "                q_means = q_outs[:,:latent_dim]\n",
    "                q_precs = torch.inverse(get_cov_mat(q_outs[:,latent_dim:],dim_obs,encoder_cov_type,device))\n",
    "                batch_means.append(q_means)\n",
    "                batch_precs.append(q_precs)\n",
    "                means, precs = product_of_gaussians(q_means.view(1,-1,latent_dim),q_precs.view(1,-1,latent_dim,latent_dim))\n",
    "                batch_prod_means.append(means)\n",
    "                batch_prod_precs.append(precs)\n",
    "                \n",
    "            means, precs = torch.stack(batch_prod_means), torch.stack(batch_prod_precs)\n",
    "            \n",
    "            thetas = torch.squeeze(means + torch.matmul(torch.inverse(precs),torch.randn_like(means)))#shape: [BxL]\n",
    "            for i in range(batch_size):\n",
    "                s,a_rb,r,sp = [torch.from_numpy(samps[i][k]).float() for k in ['o','a','r','op']]\n",
    "                if discrete_actions:\n",
    "                    a = torch.squeeze(torch.nn.functional.one_hot(torch.from_numpy(a_rb).long(),num_classes=dim_actions)).float()\n",
    "                else:\n",
    "                    a = a_rb\n",
    "                net_ins = torch.cat((s,a,thetas[i,:].expand(batch_length,latent_dim)),axis=1)\n",
    "                t_outs = trans_net(net_ins)\n",
    "                r_outs = rew_net(net_ins)\n",
    "                r_means, r_covs = r_outs[:,0], torch.clamp(r_outs[:,1],-max_variance,max_variance)\n",
    "                t_means, t_covs = t_outs[:,:dim_obs], torch.clamp(t_outs[:,dim_obs:],-max_logvar,max_logvar)\n",
    "                log_ts[i] = torch.sum(log_transition_probs(t_means,t_covs,sp,cov_type=trans_cov_type,device=device))\n",
    "                #log_rs[i] = torch.sum(log_rew_probs(r_means,r_covs,r))\n",
    "                log_rs[i] = -torch.sum(torch.nn.MSELoss()(r_outs[:,0],r))\n",
    "                q_dist = torch.distributions.MultivariateNormal(batch_means[i],precision_matrix=batch_precs[i])\n",
    "                kl_divs[i] = torch.sum(torch.distributions.kl.kl_divergence(q_dist,latent_prior.expand([batch_length])))\n",
    "            \n",
    "            loss = torch.mean(kl_divs - log_ts - log_rs)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            q_optimizer.step()\n",
    "            t_optimizer.step()\n",
    "            r_optimizer.step()\n",
    "        losses = np.append(losses,loss.cpu().detach().numpy())\n",
    "        print(torch.mean(kl_divs),torch.mean(log_ts),torch.mean(log_rs))\n",
    "        print(loss)\n",
    "\n",
    "    s, d, ep_rew = env.reset(), False, 0.\n",
    "    dyn_error, rew_error = 0, 0\n",
    "    ep_step = 0\n",
    "    while not d and ep_step < max_ep_length:\n",
    "        if epoch < random_episodes:\n",
    "            a = np.array(env.action_space.sample())\n",
    "        #else:\n",
    "            #a = policy.get_action(s)\n",
    "        sp, r, d, _ = env.step(a) # take a random action\n",
    "        s_n = s+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        sp_n = sp+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        r_n = r+np.random.normal(0.,rew_noise)\n",
    "        rb.add_sample(s_n,a,r_n,sp_n,d)\n",
    "                    \n",
    "        ep_rew += r\n",
    "        global_iters += 1\n",
    "        ep_step += 1\n",
    "        s = sp\n",
    "    rewards.append(ep_rew)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs330",
   "language": "python",
   "name": "cs330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
