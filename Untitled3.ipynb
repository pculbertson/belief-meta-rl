{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new params!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preston/Documents/school/cs330/env/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "413 ms ± 5.48 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "410 ms ± 5.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "415 ms ± 5.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e0f582ebe6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a = policy.get_action(s,[h.expand(encoder_num_layers,num_traj,encoder_hs) for h in hidden])'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/preston/Documents/school/cs330/env/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/env/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/project/belief_policies.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, hidden)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mq_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_ins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mnew_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_precs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latent_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cov_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latent_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_cov_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mcode_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_precs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_product_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcode_precs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_precs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/cs330/project/utils/distributions.py\u001b[0m in \u001b[0;36mgaussian_product_posterior\u001b[0;34m(mean_prior, prec_prior, new_mean, new_prec)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m\"\"\"adds one more Gaussian to product of Gaussians. used for computing belief posterior online.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprec_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprec_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_prec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmean_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_prior\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_prec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym, torch, meta_env\n",
    "import numpy as np\n",
    "from utils.buffer import ReplayBuffer\n",
    "from belief_models import LSTMEncoder, TransitionNet, RewardNet\n",
    "from utils.distributions import get_cov_mat, log_transition_probs, log_rew_probs, product_of_gaussians, gaussian_product_posterior\n",
    "from belief_policies import LSTMRandomShooting\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#setup environment\n",
    "env = gym.make('MetaPendulum-v0')\n",
    "if env.action_space.shape:\n",
    "    dim_actions = env.action_space.shape[0]\n",
    "    discrete_actions = False\n",
    "else:\n",
    "    dim_actions = env.action_space.n\n",
    "    discrete_actions = True\n",
    "dim_obs = env.observation_space.shape[0] if env.observation_space.shape else 1\n",
    "\n",
    "#setup buffer\n",
    "buffer_size = 10000\n",
    "if env.action_space.shape:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,dim_actions)\n",
    "else:\n",
    "    rb = ReplayBuffer(buffer_size,dim_obs,1)\n",
    "\n",
    "#training hyperparameters\n",
    "num_epochs = 5000\n",
    "global_iters = 0\n",
    "num_train_steps = 20\n",
    "max_logvar = 10.\n",
    "state_noise = 1e-3\n",
    "rew_noise = 1e-3\n",
    "random_episodes=0\n",
    "max_ep_length = 200\n",
    "episode_repeat = 3\n",
    "\n",
    "#model hyperparameters\n",
    "trans_cov_type='diag'\n",
    "trans_hs=200\n",
    "\n",
    "rew_hs=200\n",
    "\n",
    "encoder_type = 'single'\n",
    "encoder_cov_type='diag'\n",
    "encoder_hs = 200\n",
    "encoder_num_layers = 1\n",
    "latent_dim=30\n",
    "latent_prior = torch.distributions.MultivariateNormal(torch.zeros(latent_dim),torch.eye(latent_dim))\n",
    "test_batch_size = 100\n",
    "\n",
    "trans_net = TransitionNet(dim_obs,dim_actions,latent_dim,cov_type=trans_cov_type,hs=trans_hs).to(device)\n",
    "rew_net = RewardNet(dim_obs,dim_actions,latent_dim,hs=rew_hs).to(device)\n",
    "encoder = LSTMEncoder(dim_obs,dim_actions,latent_dim,cov_type=encoder_cov_type,hs=encoder_hs,num_layers=encoder_num_layers)\n",
    "\n",
    "#training parameters\n",
    "t_learning_rate = 1e-3\n",
    "t_optimizer = torch.optim.Adam(trans_net.parameters(),lr=t_learning_rate)\n",
    "\n",
    "r_learning_rate = 1e-2\n",
    "r_optimizer = torch.optim.Adam(rew_net.parameters(),lr=r_learning_rate)\n",
    "\n",
    "q_learning_rate = 1e-3\n",
    "q_optimizer = torch.optim.Adam(encoder.parameters(),lr=q_learning_rate)\n",
    "\n",
    "#planner hyperparameters\n",
    "num_traj = 300\n",
    "traj_length = 20\n",
    "num_iters = 5\n",
    "elite_frac = 0.1\n",
    "\n",
    "batch_size = 50\n",
    "batch_length = traj_length\n",
    "\n",
    "if env.action_space.shape:\n",
    "    init_action_dist = torch.distributions.MultivariateNormal(torch.zeros(dim_actions),torch.from_numpy((env.action_space.high-env.action_space.low)**2)*torch.eye(dim_actions))\n",
    "    action_dist = [init_action_dist]*(traj_length-1)\n",
    "else:\n",
    "    init_action_dist = torch.distributions.Categorical(logits=torch.ones(env.action_space.n))\n",
    "    action_dist = [init_action_dist]*(traj_length-1)\n",
    "    \n",
    "policy = LSTMRandomShooting(trans_net, rew_net, encoder, init_action_dist, num_traj, traj_length, dim_obs, dim_actions, latent_dim, trans_cov_type, False, encoder_cov_type, max_logvar, device, det=False)\n",
    "losses = np.array([])\n",
    "rewards = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % episode_repeat == 0:\n",
    "        print('new params!')\n",
    "        m, l = np.random.uniform(0.1,50.), np.random.uniform(0.5,10.)\n",
    "        env.set_params(m,l)\n",
    "    rb.new_episode()\n",
    "    if epoch > 0:\n",
    "        for step in range(num_train_steps):\n",
    "            samps = rb.random_sequences(batch_size,batch_length)\n",
    "            \n",
    "            q_optimizer.zero_grad()\n",
    "            t_optimizer.zero_grad()\n",
    "            r_optimizer.zero_grad()\n",
    "            \n",
    "            kl_divs, log_ts, log_rs = torch.zeros(batch_size), torch.zeros(batch_size), torch.zeros(batch_size)\n",
    "        \n",
    "            #assuming all sequences are full-length\n",
    "            s,a_rb,r,sp = [torch.stack([torch.from_numpy(samp[k]).float() for samp in samps]) for k in ['o','a','r','op']]\n",
    "            \n",
    "            if discrete_actions:\n",
    "                a = torch.squeeze(torch.nn.functional.one_hot(torch.from_numpy(a_rb).long(),num_classes=dim_actions)).float()\n",
    "            else:\n",
    "                a = a_rb\n",
    "            \n",
    "            q_ins = torch.cat((s,a,r,sp),axis=2)\n",
    "            q_outs, _ = encoder(q_ins)\n",
    "            q_means = torch.squeeze(q_outs)[:,:,:latent_dim]\n",
    "            q_precs = torch.inverse(get_cov_mat(q_outs[:,:,latent_dim:],dim_obs,encoder_cov_type,device))\n",
    "                \n",
    "            post_means, post_precs = product_of_gaussians(q_means,q_precs)\n",
    "            products_zipped = [product_of_gaussians(q_means[:,:t],q_precs[:,:t,:,:]) for t in range(1,batch_length+1)]\n",
    "            stepwise_means = torch.squeeze(torch.stack([a[0] for a in products_zipped],axis=1))\n",
    "            stepwise_precs = torch.stack([a[1] for a in products_zipped],axis=1)\n",
    "            \n",
    "            thetas = (post_means + torch.matmul(torch.inverse(post_precs),torch.randn_like(post_means))).view(batch_size,1,-1)#shape: [BxL]\n",
    "            \n",
    "            net_ins = torch.cat((s,a,thetas.expand(batch_size,batch_length,latent_dim)),axis=2)\n",
    "            t_outs = trans_net(net_ins)\n",
    "            r_outs = rew_net(net_ins)\n",
    "            r_means, r_covs = r_outs[:,:,0], torch.clamp(r_outs[:,:,1],-max_logvar,max_logvar)\n",
    "            t_means, t_covs = t_outs[:,:,:dim_obs], torch.clamp(t_outs[:,:,dim_obs:],-max_logvar,max_logvar)\n",
    "            log_ts = torch.sum(log_transition_probs(t_means,t_covs,sp,cov_type=trans_cov_type,device=device),1)\n",
    "            t_mse = torch.nn.MSELoss()(t_means,sp)\n",
    "            log_rs = -torch.sum(torch.nn.MSELoss(reduction='none')(r_outs[:,:,0],torch.squeeze(r)),1)\n",
    "        \n",
    "            prior_dist = torch.distributions.MultivariateNormal(stepwise_means[:,:-1,:],precision_matrix=stepwise_precs[:,:-1,:,:])\n",
    "            post_dist = torch.distributions.MultivariateNormal(stepwise_means[:,1:,:],precision_matrix=stepwise_precs[:,1:,:,:])\n",
    "            kl_divs = torch.sum(torch.distributions.kl.kl_divergence(post_dist,prior_dist))\n",
    "            \n",
    "            loss = torch.mean(kl_divs - log_ts - log_rs)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            q_optimizer.step()\n",
    "            t_optimizer.step()\n",
    "            r_optimizer.step()\n",
    "            print(step)\n",
    "        losses = np.append(losses,loss.cpu().detach().numpy())\n",
    "        print(torch.mean(kl_divs),torch.mean(log_ts),torch.mean(log_rs))\n",
    "        print('mse: ', t_mse)\n",
    "        print(loss)\n",
    "\n",
    "    s, d, ep_rew = env.reset(), False, 0.\n",
    "    dyn_error, rew_error = 0, 0\n",
    "    ep_step = 0\n",
    "    latent_mean, latent_prec = torch.zeros(latent_dim).view(1,latent_dim,1), torch.eye(latent_dim).view(1,latent_dim,latent_dim)\n",
    "    hidden = None\n",
    "    while not d and ep_step < max_ep_length:\n",
    "        \n",
    "        if epoch < random_episodes:# or epoch % episode_repeat == 0:\n",
    "            a = np.array(env.action_space.sample())\n",
    "            #a = policy.get_action(s,hidden)\n",
    "        else:\n",
    "            if hidden is None:\n",
    "                a = policy.get_action(s,hidden)\n",
    "            else:\n",
    "                %timeit a = policy.get_action(s,[h.expand(encoder_num_layers,num_traj,encoder_hs) for h in hidden])\n",
    "        \n",
    "        sp, r, d, _ = env.step(a) # take a random action\n",
    "        s_n = s+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        sp_n = sp+np.random.multivariate_normal(np.zeros(dim_obs),state_noise*np.eye(dim_obs))\n",
    "        r_n = r+np.random.normal(0.,rew_noise)\n",
    "        rb.add_sample(s_n,a,r_n,sp_n,d)\n",
    "        \n",
    "        codes = torch.squeeze(latent_mean.expand(test_batch_size,latent_dim,1) + torch.matmul(torch.inverse(latent_prec).expand(test_batch_size,latent_dim,latent_dim),torch.randn(test_batch_size,latent_dim,1)))\n",
    "        s_torch = torch.from_numpy(np.array(s)).float().expand(test_batch_size,dim_obs)\n",
    "        a_torch = torch.from_numpy(np.array(a)).float().expand(test_batch_size,dim_actions)\n",
    "        net_ins = torch.cat((s_torch,a_torch,codes),axis=1)\n",
    "        \n",
    "        sp_hats = trans_net(net_ins)[:,:dim_obs]\n",
    "        r_hats = rew_net(net_ins)[:,0]\n",
    "        \n",
    "        t_err = torch.mean(torch.nn.MSELoss()(torch.from_numpy(sp).float().expand(test_batch_size,dim_obs),sp_hats))\n",
    "        r_err = torch.mean(torch.nn.MSELoss()(torch.from_numpy(np.array([r])).float().expand(test_batch_size,1),r_hats))\n",
    "        \n",
    "        dyn_error += t_err\n",
    "        rew_error += r_err\n",
    "        \n",
    "        q_in = torch.cat([torch.from_numpy(np.array(k)).float() for k in [s,a,[r],sp]]).view(1,1,-1)\n",
    "        q_out, hidden = encoder(q_in,hidden)\n",
    "        new_mean, new_prec = torch.squeeze(q_out)[:latent_dim].view(1,latent_dim,1), torch.inverse(get_cov_mat(torch.squeeze(q_out)[latent_dim:],dim_obs,encoder_cov_type,device)).view(1,latent_dim,latent_dim)     \n",
    "        latent_mean, latent_prec = gaussian_product_posterior(latent_mean,latent_prec,new_mean,new_prec)\n",
    "        \n",
    "        if ep_step == 5:\n",
    "            print('trans: ', sp, torch.mean(sp_hats,0))\n",
    "            print('r: ', r, torch.mean(r_hats,0))    \n",
    "        \n",
    "        ep_rew += r\n",
    "        global_iters += 1\n",
    "        ep_step += 1\n",
    "        s = sp\n",
    "    rewards.append(ep_rew)\n",
    "    print('ep_rew: ', ep_rew)\n",
    "    print('traj errors: ', dyn_error,rew_error)\n",
    "    #print(t_err,r_err)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs330",
   "language": "python",
   "name": "cs330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
